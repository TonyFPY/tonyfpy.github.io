<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Machine Learning on Tony Feng</title>
        <link>https://tonyfpy.github.io/tags/machine-learning/</link>
        <description>Recent content in Machine Learning on Tony Feng</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Mon, 02 May 2022 23:09:54 +0800</lastBuildDate><atom:link href="https://tonyfpy.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[Machine Learning] Topic 1: Linear Regression</title>
        <link>https://tonyfpy.github.io/p/machine-learning-topic-1-linear-regression/</link>
        <pubDate>Mon, 02 May 2022 23:09:54 +0800</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-topic-1-linear-regression/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on May 2nd, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on May 5th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Linear Regression&lt;/strong&gt; is studied as a model for understanding the relationship between input and output numerical variables. It is classified as a supervised learning problem, whose goal is to learn a function/hypothesis $ h: X \rarr Y $ so that $ h(x) $ is a “good” predictor for the corresponding value of $ y $.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;notations&#34;&gt;Notations&lt;/h2&gt;
&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$ x^{(i)} $ denotes the input variables or features, and $ y^{(i)} $ denotes the output variable that we’re trying to predict, where the superscript $ i $ denotes the $ i^{th} $ training sample.&lt;/li&gt;
&lt;li&gt;A pair $ (x^{(i)}, y^{(i)}) $ denotes a single training example.&lt;/li&gt;
&lt;li&gt;$ x^{(i)}_j $ represents the $ j^{th} $ feature of the $ i^{th} $ training sample.&lt;/li&gt;
&lt;li&gt;$ m $ denotes &lt;strong&gt;the number of training examples&lt;/strong&gt;, while $ n $ denotes &lt;strong&gt;the number of features&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;hypothesis-function&#34;&gt;Hypothesis Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$ h_{\theta}(x) $ denotes the hypothesis function, which is a linear function of the features $ x $ and $ x_0=1 $.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cost-function&#34;&gt;Cost Function&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;$ J_{\theta} $ denotes the cost function that we want to minimize by finding the optimal set of parameters $ \theta $.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hypothesis-function-1&#34;&gt;Hypothesis Function&lt;/h2&gt;
&lt;h3 id=&#34;initial-representation&#34;&gt;Initial Representation&lt;/h3&gt;
&lt;p&gt;Given a set of data, let&amp;rsquo;s say we want to approximate $ y $ as a linear function of $ x $:&lt;/p&gt;
&lt;p&gt;$$ h_{\theta}(x) = {\theta}_0 + {\theta}_1x_1 + {\theta}_2x_2 + &amp;hellip; + {\theta}_nx_n $$&lt;/p&gt;
&lt;p&gt;, where the $ {\theta}_j $&amp;rsquo;s are the parameters (also called &lt;strong&gt;weights&lt;/strong&gt;) parameterizing the space of linear functions mapping from $ X $ to $ Y $.&lt;/p&gt;
&lt;h3 id=&#34;representation-improvement&#34;&gt;Representation Improvement&lt;/h3&gt;
&lt;p&gt;To make it simplied, we introduce an &lt;strong&gt;intercept term&lt;/strong&gt; $ x_0=1 $ such that:&lt;/p&gt;
&lt;p&gt;$$ h(x) =  \sum_{j=0}^{n} {\theta}_jx_j = {\theta}^Tx $$&lt;/p&gt;
&lt;p&gt;, where on the right-hand side above we are viewing $ {\theta} $ and $ x $ both as vectors.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cost-function-1&#34;&gt;Cost Function&lt;/h2&gt;
&lt;h3 id=&#34;error-interpretation&#34;&gt;Error Interpretation&lt;/h3&gt;
&lt;p&gt;The hypothesis may not capture unmodeled effects or random noise, so we can say:&lt;/p&gt;
&lt;p&gt;$$ y^{(i)} = {\theta}^Tx^{(i)} + {\epsilon}^{(i)} $$&lt;/p&gt;
&lt;p&gt;Let’s further assume that $ {\epsilon}^{(i)} $ follows a &lt;strong&gt;Gaussian distribution (Normal distribution)&lt;/strong&gt; with mean $ {\mu}=0 $ and variance $ {\sigma}^2 $. This could be expressed as $ {\epsilon}^{(i)} {\sim} N(0, {\sigma}^2)$. This implies that the probability density of $ {\epsilon}^{(i)} $ follows a Gaussian density function as follows:&lt;/p&gt;
&lt;p&gt;$$ P({\epsilon}^{(i)}) = \frac{1}{\sqrt{2 \pi} \sigma} exp (-\frac{({\epsilon}^{(i)})^2}{2 \sigma^{2}}) $$&lt;/p&gt;
&lt;p&gt;Another assumption we’re going to make is that the $ {\epsilon}^{(i)} $ error terms are &lt;strong&gt;IID&lt;/strong&gt;, which in statistics stands for &lt;strong&gt;independently and identically distributed&lt;/strong&gt;. Under these set of assumptions, the probability density of $ y^{(i)} $ given $ x^{(i)} $ and parameterized by $ {\theta} $:&lt;/p&gt;
&lt;p&gt;$$ P(y^{(i)} \mid x^{(i)} ; \theta)=\frac{1}{\sqrt{2 \pi} \sigma} exp (-\frac{(y^{(i)}-\theta^{T} x^{(i)})^{2}}{2 \sigma^{2}}) $$&lt;/p&gt;
&lt;p&gt;In other words, given $ x^{(i)} $ and $ {\theta} $, the random variable $ y^{(i)} $ is sampled from a Gaussian Distribution $ N({\theta}^Tx^{(i)}, {\sigma}^{2}) $.&lt;/p&gt;
&lt;h3 id=&#34;likelihood-function&#34;&gt;Likelihood Function&lt;/h3&gt;
&lt;p&gt;Given the input features matrix (design matrix) $ X $ (All $ x^{(i)} $ and $ {\theta} $), the probability distribution of $ \vec{y} $ (All $ y^{(i)} $’s) is given by $ P(\vec{y}∣X;{\theta}) $. The likelikhood of the parameters $ L({\theta}) $ is defined as:&lt;/p&gt;
&lt;p&gt;$$ L(\theta) =P(\vec{y} \mid X ; \theta) =\prod_{i=1}^{m} P(y^{(i)} \mid x^{(i)} ; \theta) $$&lt;/p&gt;
&lt;p&gt;Now, we add details into the above equation,
$$
L(\theta)=\prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi} \sigma} exp (-\frac{(y^{(i)}-\theta^{T} x^{(i)})^{2}}{2 \sigma^{2}})
$$&lt;/p&gt;
&lt;p&gt;The principal of &lt;strong&gt;Maximum Likelihood Estimation (MLE)&lt;/strong&gt; states that we should choose $ {\theta} $ so as to make the data as high probability as possible. The derivations will be a bit simpler if we instead maximize the log likelihood $ {\ell(\theta)} $:&lt;/p&gt;
&lt;p&gt;$$
{\ell(\theta)}=ln(\prod_{i=1}^{m} \frac{1}{\sqrt{2 \pi} \sigma} exp (-\frac{(y^{(i)}-\theta^{T} x^{(i)})^{2}}{2 \sigma^{2}}))
$$&lt;/p&gt;
&lt;p&gt;According to the product rule of logarithms,&lt;/p&gt;
&lt;p&gt;$$
\ell(\theta)=\sum_{i=1}^{m} ln \frac{1}{\sqrt{2 \pi} \sigma} exp (-\frac{(y^{(i)}-\theta^{T} x^{(i)})^{2}}{2 \sigma^{2}})
$$&lt;/p&gt;
&lt;p&gt;Again, the log product rule shows us:&lt;/p&gt;
&lt;p&gt;$$
\ell(\theta)=\sum_{i=1}^{m} \left[ln \frac{1}{\sqrt{2 \pi} \sigma} + ln(exp (-\frac{(y^{(i)}-\theta^{T} x^{(i)})^{2}}{2 \sigma^{2}})\right]
$$&lt;/p&gt;
&lt;p&gt;This could be expanded as:&lt;/p&gt;
&lt;p&gt;$$
\ell(\theta)= m {\cdot} ln \frac{1}{\sqrt{2 \pi} \sigma} - \frac{1}{\sigma^{2}} {\cdot} \frac{1}{2} {\cdot} \sum_{i=1}^{m} (y^{(i)}-\theta^{T} x^{(i)})^{2}
$$&lt;/p&gt;
&lt;h3 id=&#34;cost-function-formation&#34;&gt;Cost Function Formation&lt;/h3&gt;
&lt;p&gt;From the probability interpretation above, we could regard $ \ell(\theta) $ as:&lt;/p&gt;
&lt;p&gt;$$
\ell(\theta)= C_1 - C_2 {\cdot} \frac{1}{2} {\cdot} \sum_{i=1}^{m} (y^{(i)}-\theta^{T} x^{(i)})^{2}
$$&lt;/p&gt;
&lt;p&gt;, where $ C_1 $ and $ C_2 $ are constant. Hence, maximizing $ \ell(\theta) $ is equivalent to minimizing $ J(\theta) $:&lt;/p&gt;
&lt;p&gt;$$
J(\theta)= \frac{1}{2} {\cdot} \sum_{i=1}^{m} (y^{(i)}-\theta^{T} x^{(i)})^{2}
$$&lt;/p&gt;
&lt;p&gt;, where $ 1/2 $ is a constant that helps cancel 2 in derivative of the function.&lt;/p&gt;
&lt;p&gt;The formation above shows that choosing the value of $ \theta $ to minimize the &lt;strong&gt;least squares error cost function&lt;/strong&gt;, is equivalent to finding the &lt;strong&gt;MLE&lt;/strong&gt; for the parameters $ \theta $ under the set of assumptions that the error terms $ {\epsilon}^{(i)} $ are &lt;strong&gt;Gaussian&lt;/strong&gt; and &lt;strong&gt;IID&lt;/strong&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;gradient-descent&#34;&gt;Gradient Descent&lt;/h2&gt;
&lt;h3 id=&#34;least-mean-square&#34;&gt;Least Mean Square&lt;/h3&gt;
&lt;p&gt;To find a set of parameters, one way is to find the optimum that minimizes the cost function. Therefore, we need $ \nabla_{\theta} J(\theta)= 0 $. More specifically, $ \frac{\partial J}{\partial \theta_{1}} = 0, \frac{\partial J}{\partial \theta_{2}} = 0, \frac{\partial J}{\partial \theta_{3}} = 0, &amp;hellip;, \frac{\partial J}{\partial \theta_{n}} = 0 $.&lt;/p&gt;
&lt;p&gt;However, this may generate $ n $ equations and is computationally expensive if there are many features in the dataset. We need to find other ways.&lt;/p&gt;
&lt;h3 id=&#34;gradient-descent-1&#34;&gt;Gradient Descent&lt;/h3&gt;
&lt;p&gt;We can start with some “initial guess” for $ {\theta} $, and that repeatedly changes $ {\theta} $ to make $ J(\theta) $ smaller, until hopefully we converge to a value of $ {\theta} $ that minimizes $ J(\theta) $. For $ j = 0, 1, 2, &amp;hellip;, n $, we &lt;strong&gt;simultaneously&lt;/strong&gt; update the $ {\theta} $ and this process will be kept until convergence:&lt;/p&gt;
&lt;p&gt;$$ \theta _{j} \gets \theta _{j} - \alpha \cdot \frac{\partial J}{\partial \theta _{j}}  $$&lt;/p&gt;
&lt;p&gt;Here, $ \alpha$ is the learning rate, a hyperparameter to control the searching speed. Now, we put all the equations together and we coud see:&lt;/p&gt;
&lt;p&gt;$$ \theta_{j}\gets \theta_{j}+\alpha \cdot \sum_{i=1}^{m}(y^{(i)}-h_{\theta}(x^{(i)})) x_{j}^{(i)} $$&lt;/p&gt;
&lt;p&gt;This is the &lt;strong&gt;Stochastic Gradient Descent&lt;/strong&gt; strategy, because we update the parameters according to the gradient of the error with respect to a single training example only. Beside, there are other strategies, such as &lt;strong&gt;Batch GD&lt;/strong&gt;, &lt;strong&gt;Mini-batch GD&lt;/strong&gt;, etc, which will be discussed in my future posts.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;normal-equation&#34;&gt;Normal Equation&lt;/h2&gt;
&lt;p&gt;In this method, we will minimize $ J(\theta) $ by explicitly taking its derivatives with respect to the $ {\theta}_j $’s, and setting them to zero.&lt;/p&gt;
&lt;p&gt;Given a training set, define the design matrix $ X $ to be the $ m×n $, and let $ y $ to be the $ m×1 $ vector containing all the target values from the training set. We can obtain:&lt;/p&gt;
&lt;p&gt;$$
J(\theta)= \frac{1}{2} {\cdot} \sum_{i=1}^{m} (y^{(i)}-\theta^{T} x^{(i)})^{2} = \frac{1}{2} || X\theta-y || ^2 = \frac{1}{2} (X \theta-y)^{T}(X \theta-y)
$$&lt;/p&gt;
&lt;p&gt;Now, we expand the equation:&lt;/p&gt;
&lt;p&gt;$$
J(\theta)= \frac{1}{2} (\theta^{T} X^{T} X \theta-\theta^{T} X^{T} y-y^{T} X \theta + y^{T} y)
$$&lt;/p&gt;
&lt;p&gt;Since $ \theta^{T} X^{T} y $ and $ y^{T} X \theta $ are scalars, so they are equivalent. We can now simplify the equation as:&lt;/p&gt;
&lt;p&gt;$$
J(\theta)= \frac{1}{2} (\theta^{T} X^{T} X \theta-2\theta^{T} X^{T} y + y^{T} y)
$$&lt;/p&gt;
&lt;p&gt;Accoding to the rules of derivative of matrix, $ \frac{d B^{T} A B}{d B}=(A+A^{\mathrm{T}}) B $ and $ \frac{d B^{T} A}{d B}=A $, we can find its derivatives with respect to $ \theta $:&lt;/p&gt;
&lt;p&gt;$$
\nabla_{\theta} J(\theta)= \frac{1}{2} ((X^TX + (X^TX)^T)\theta - 2X^Ty) = \frac{1}{2} (2X^TX\theta - 2X^Ty)
$$&lt;/p&gt;
&lt;p&gt;Now, we set $ \nabla_{\theta} J(\theta) $ to zero:&lt;/p&gt;
&lt;p&gt;$$
X^TX\theta = X^Ty
$$&lt;/p&gt;
&lt;p&gt;Thus, the value of $ \theta $ that minimizes $ J(\theta) $ is given in closed form by the equation:&lt;/p&gt;
&lt;p&gt;$$
\theta=(X^{T} X)^{-1} X^{T} y
$$&lt;/p&gt;
&lt;p&gt;This approach requires the matrix to be &lt;strong&gt;inversible&lt;/strong&gt;. Usually, if some features have linear relations or the size of training samples is smaller than the number of features, $ X^TX $ is not inversible.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.seldon.io/machine-learning-regression-explained#:~:text=Regression%20is%20a%20technique%20for,used%20to%20predict%20continuous%20outcomes.&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Machine Learning Regression Explained&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://machinelearningmastery.com/linear-regression-for-machine-learning/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Linear Regression for Machine Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Logistic Regression — Detailed Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://medium.com/swlh/ml-fundamentals-what-is-cost-function-d396129cc611&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Fundamentals: What Is Cost Function?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://scruel.gitee.io/ml-andrewng-notes&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Andrew Ng Notes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
