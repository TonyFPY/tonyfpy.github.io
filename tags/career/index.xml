<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Career on Tony Feng</title>
        <link>https://tonyfpy.github.io/tags/career/</link>
        <description>Recent content in Career on Tony Feng</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <lastBuildDate>Wed, 26 Oct 2022 21:39:49 -0400</lastBuildDate><atom:link href="https://tonyfpy.github.io/tags/career/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[Career Talk] Behavioral Questions Preparation</title>
        <link>https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/</link>
        <pubDate>Wed, 26 Oct 2022 21:39:49 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 26th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 29th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;If you’re preparing for the tech role interview, the behavioral round is one type of interview that you cannot overlook. Interviewers use open-ended questions to find out if you match the company&amp;rsquo;s values and are a good fit for the role.&lt;/p&gt;
&lt;p&gt;Usually, it is recommended to anser the questions according to &lt;strong&gt;S&lt;/strong&gt;ituation,  &lt;strong&gt;T&lt;/strong&gt;ask, &lt;strong&gt;A&lt;/strong&gt;ction, &lt;strong&gt;R&lt;/strong&gt;esult (&lt;strong&gt;STAR&lt;/strong&gt;). For example, &lt;strong&gt;&amp;ldquo;Tell me about a time that you led a challenging project?&amp;rdquo;&lt;/strong&gt; You can answer like this:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;[TASK]&lt;/strong&gt; Last year, I was tasked with growing our latest SaaS app&amp;rsquo;s sales. &lt;strong&gt;[SITUATION]&lt;/strong&gt; The company had just released a new version of the product and we needed to get media coverage and drive more sales. &lt;strong&gt;[ACTION]&lt;/strong&gt; I worked with some of our largest clients to ensure that they had a smooth transition to the new version. &lt;strong&gt;[RESULT]&lt;/strong&gt; We really had a spike in sales of 25% and added over a hundred new customers during the launch week.&lt;/p&gt;
&lt;p&gt;In this post, I will briefly go through the famous &lt;strong&gt;Amazon’s Leadership Principles&lt;/strong&gt; with corresponding behavioral questions. Hopefully, this post can help you (me) to practice the &lt;strong&gt;STAR&lt;/strong&gt; approach based on past experiences.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;principles&#34;&gt;Principles&lt;/h2&gt;
&lt;h3 id=&#34;are-right-a-lot&#34;&gt;Are Right, A Lot&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/1.jpg&#34;
	width=&#34;1826&#34;
	height=&#34;710&#34;
	srcset=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/1_hu296c7977af8197dc9c0fc7795eb80d41_147310_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/1_hu296c7977af8197dc9c0fc7795eb80d41_147310_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;257&#34;
		data-flex-basis=&#34;617px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;决策时，信息太多，怎么办？&lt;/li&gt;
&lt;li&gt;决策时，信息太少，怎么办？&lt;/li&gt;
&lt;li&gt;决策后，发现错误，怎么办？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you didn&amp;rsquo;t have enough data to make the right decision.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What did you do?&lt;/li&gt;
&lt;li&gt;What path did you take?&lt;/li&gt;
&lt;li&gt;Did the decision turn out to be the correct one?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you discovered that your idea was not the best course of action.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What was your idea? Why wasn&amp;rsquo;t your idea the best course of action? How did - you find out it was not the correct path? What was the best course of action?&lt;/li&gt;
&lt;li&gt;Who provided it? What did you learn from the experience?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Describe a time when you brought different perspectives together to solve a problem.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What types of different perspectives were represented?&lt;/li&gt;
&lt;li&gt;How did you seek out different points of view?&lt;/li&gt;
&lt;li&gt;What was the outcome?&lt;/li&gt;
&lt;li&gt;Were there any key learnings from this experience?&lt;/li&gt;
&lt;li&gt;Knowing what you know now, would you have done anything different?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;bias-for-action&#34;&gt;Bias for Action&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/2.jpg&#34;
	width=&#34;1884&#34;
	height=&#34;812&#34;
	srcset=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/2_hueb55b0cb94d23baab1e4ee3502b5f505_122297_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/2_hueb55b0cb94d23baab1e4ee3502b5f505_122297_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;232&#34;
		data-flex-basis=&#34;556px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;时间紧迫，信息不足，是继续收集信息还是直接决策？如何考虑风险？&lt;/li&gt;
&lt;li&gt;时间紧迫，未咨询过上级而直接决策，如何处理？&lt;/li&gt;
&lt;li&gt;团队进度缓慢，如何解决？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you worked against tight deadlines and didn&amp;rsquo;t have time to consider all options before making a decision.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How much time did you have?&lt;/li&gt;
&lt;li&gt;What approach did you take?&lt;/li&gt;
&lt;li&gt;What did you learn from the situation?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Describe a situation where you made an important business decision without consulting your manager.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What was the situation&lt;/li&gt;
&lt;li&gt;How did it turn out?&lt;/li&gt;
&lt;li&gt;Would you have done anything differently?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you felt your team was not moving to action quickly enough.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What was the situation?&lt;/li&gt;
&lt;li&gt;What did you do?&lt;/li&gt;
&lt;li&gt;What was the outcome?&lt;/li&gt;
&lt;li&gt;Would you have done anything differently?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;customer-obsession&#34;&gt;Customer Obsession&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/3.jpg&#34;
	width=&#34;1952&#34;
	height=&#34;1070&#34;
	srcset=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/3_hueb4a4659c92846758d8091bb473e36c6_143270_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/3_hueb4a4659c92846758d8091bb473e36c6_143270_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;437px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如何发现和挖掘需求？&lt;/li&gt;
&lt;li&gt;如何根据反馈去解决需求？&lt;/li&gt;
&lt;li&gt;如何平衡客户需求和公司需求？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Describe a difficult interaction you had with a customer.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How did you deal with it?&lt;/li&gt;
&lt;li&gt;What was the outcome?&lt;/li&gt;
&lt;li&gt;How would you handle it differently?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you evaluated the customer experience of your product or service.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What did you do?&lt;/li&gt;
&lt;li&gt;What was the result?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you had to balance the needs of the customer with the needs of the business.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What did you do?&lt;/li&gt;
&lt;li&gt;What was the result?&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;deliver-results&#34;&gt;Deliver Results&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/4.jpg&#34;
	width=&#34;1902&#34;
	height=&#34;674&#34;
	srcset=&#34;https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/4_hucad153ff45005c8b425b77c608856b6a_151999_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/career-talk-behavioral-questions-preparation/4_hucad153ff45005c8b425b77c608856b6a_151999_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;282&#34;
		data-flex-basis=&#34;677px&#34;
	
&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Summary&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;发现目标无法达成或者无法在规定时间内达成，怎么办？&lt;/li&gt;
&lt;li&gt;发现目标远远超出预期，如何复盘？&lt;/li&gt;
&lt;li&gt;如何设定合理但具有挑战的目标？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you or your team were more than half way to meeting a goal when you realized it may not be the right goal or may have unintended consequences.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What was the situation?&lt;/li&gt;
&lt;li&gt;What did you do? What was the outcome?&lt;/li&gt;
&lt;li&gt;Looking back, would you have done anything differently?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Tell me about a time when you not only met a goal but considerably exceeded expectations.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How were you able to do it?&lt;/li&gt;
&lt;li&gt;What challenges did you have to overcome?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;It can be difficult to set goals for a team that are challenging, yet achievable. Tell me about a time when you hit the right balance.&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How did you approach setting the goals?&lt;/li&gt;
&lt;li&gt;What was the outcome?&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Machine Learning] Interview Questions - Part 5</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-5/</link>
        <pubDate>Mon, 10 Oct 2022 23:14:27 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-5/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 10th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 13th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) Feature Engineering Techniques for Machine Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feature selection
&lt;ul&gt;
&lt;li&gt;Correlation matrix with heatmap&lt;/li&gt;
&lt;li&gt;Statistical tests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Exploratory Data Analysis&lt;/li&gt;
&lt;li&gt;Handling imbalanced data
&lt;ul&gt;
&lt;li&gt;Under-sampling majority class&lt;/li&gt;
&lt;li&gt;Over-Sampling Minority class&lt;/li&gt;
&lt;li&gt;Data augmentaion&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Imputation (handling missing values)
&lt;ul&gt;
&lt;li&gt;Apply mean, median to numerical values&lt;/li&gt;
&lt;li&gt;Apply mode to categorical values&lt;/li&gt;
&lt;li&gt;Drop NA values entire rows&lt;/li&gt;
&lt;li&gt;Drop NA values entire features&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Handling Outliers
&lt;ul&gt;
&lt;li&gt;Removal&lt;/li&gt;
&lt;li&gt;Replacing values&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Feature scaling
&lt;ul&gt;
&lt;li&gt;Standardization&lt;/li&gt;
&lt;li&gt;Normalization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Encoding
&lt;ul&gt;
&lt;li&gt;Label Encoding (text -&amp;gt; number)&lt;/li&gt;
&lt;li&gt;One-Hot Encoding (categorical -&amp;gt; numerical)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2) Is logistic regression a concave or convex function? Does it have a global optimum?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a class=&#34;link&#34; href=&#34;https://baozoulin.gitbook.io/neural-networks-and-deep-learning/neural-networks-and-deep-learning/week-2/logistic-regression-cost-function&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;error function&lt;/a&gt; minimized in logistic regression is a &lt;strong&gt;convex&lt;/strong&gt; function, so it has a global optimum.&lt;/p&gt;
&lt;p&gt;The prediction of logistic regression is non-linear (due to the sigmoid transform). Squaring this prediction like &lt;strong&gt;MSE&lt;/strong&gt; results in a &lt;strong&gt;non-convex&lt;/strong&gt; function with many local minimums, which makes it difficult to find the global minimum. Instead, using &lt;strong&gt;MLE&lt;/strong&gt; in logistic regression as the cost function is &lt;strong&gt;convex&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The proof could be found &lt;a class=&#34;link&#34; href=&#34;http://mathgotchas.blogspot.com/2011/10/why-is-error-function-minimized-in.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3) KNN vs. K-means&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;KNN represents a &lt;strong&gt;supervised&lt;/strong&gt; &lt;strong&gt;classification&lt;/strong&gt; algorithm that will give new data points accordingly to the k number or the closest data points. (It creates classes.)&lt;/p&gt;
&lt;p&gt;k-means clustering is an &lt;strong&gt;unsupervised&lt;/strong&gt; &lt;strong&gt;clustering&lt;/strong&gt; algorithm that gathers and groups data into k number of clusters. (The classes are already created.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) How to detect overfitting?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Emperical way: Performance on training set &amp;raquo; Performance on testing set&lt;/li&gt;
&lt;li&gt;Intutive way: We should prefer simple models with fewer coefficients over complex models(Occam&amp;rsquo;s Razor principle)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5) What will happen if we increase the batch of SGD (e.g. from 16 to full data size)?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Slow and computationally expensive&lt;/li&gt;
&lt;li&gt;Good for converge&lt;/li&gt;
&lt;li&gt;Slow to converge&lt;/li&gt;
&lt;li&gt;Might be trapped into local minima&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;6) Activation Functions&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linear or Identity Activation Function&lt;/li&gt;
&lt;li&gt;Non-linear Activation Function
&lt;ul&gt;
&lt;li&gt;Sigmoid: [0, 1], differentiable, monotonic&lt;/li&gt;
&lt;li&gt;Tanh: [-1, 1], differentiable, monotonic&lt;/li&gt;
&lt;li&gt;ReLU: [0, inf], monotonic&lt;/li&gt;
&lt;li&gt;Leaky ReLU: [-inf, inf], monotonic&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A neural network without an non-linear activation function is essentially just a linear regression model. The activation function does the &lt;strong&gt;non-linear transformation&lt;/strong&gt; to the input making it capable to learn and perform more complex tasks.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;Activation Functions in Neural Networks&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7) Optimization Algorithms&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Two common tools to improve gradient descent are &lt;strong&gt;the sum of gradient&lt;/strong&gt; (first moment) and &lt;strong&gt;the sum of the gradient squared&lt;/strong&gt; (second moment).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Momentum&lt;/strong&gt; method uses the first moment with a decay rate to gain speed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AdaGrad&lt;/strong&gt; uses the second moment with no decay to deal with sparse features.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;RMSProp&lt;/strong&gt; uses the second moment with a decay rate to speed up from AdaGrad.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adam&lt;/strong&gt; uses both first and second moments, and &lt;strong&gt;is generally the best choice&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8) Define LSTM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;LSTM is short for &lt;strong&gt;Long Short Term Memory&lt;/strong&gt;. It is derived from recurrent neural network and is designed to address the &lt;strong&gt;long term dependency problem&lt;/strong&gt;, by maintaining a state what to remember and what to forget.&lt;/p&gt;
&lt;p&gt;Generally, it has three key components&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gates (Forget, Memory, Update &amp;amp; Read)&lt;/li&gt;
&lt;li&gt;Tanh(x) (values between -1 to 1)&lt;/li&gt;
&lt;li&gt;Sigmoid(x) (values between 0 to 1)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;9) What is Confusion Matrix?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A confusion matrix is a table that is often used to describe the performance of a classification model on a set of test data.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;rows&lt;/strong&gt; represent the &lt;strong&gt;actual classes&lt;/strong&gt; the outcomes should have been. While the &lt;strong&gt;columns&lt;/strong&gt; represent the &lt;strong&gt;predictions&lt;/strong&gt; we have made. Using this table it is easy to see which predictions are wrong.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) Explain SVM&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Support Vector Machine, abbreviated as SVM can be used for both &lt;strong&gt;regression&lt;/strong&gt; and &lt;strong&gt;classification&lt;/strong&gt; tasks. But, it is widely used in classification objectives. The objective of the support vector machine algorithm is to find a &lt;strong&gt;hyperplane&lt;/strong&gt; in an N-dimensional space that distinctly classifies the data points.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hyperplanes&lt;/strong&gt; are &lt;strong&gt;decision boundaries&lt;/strong&gt; that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Support vectors&lt;/strong&gt; are data points that are closer to the hyperplane and influence the &lt;strong&gt;position&lt;/strong&gt; and &lt;strong&gt;orientation&lt;/strong&gt; of the hyperplane. Using these support vectors, we &lt;strong&gt;maximize the margin&lt;/strong&gt; of the boundaries.&lt;/p&gt;
&lt;p&gt;It can handle highly non-linear problems using a &lt;strong&gt;kernel trick&lt;/strong&gt; which implicitly maps the input vectors to higher-dimensional feature spaces. The &amp;ldquo;trick&amp;rdquo; is that kernel methods represent the data only through a set of &lt;strong&gt;pairwise similarity comparisons&lt;/strong&gt; between the original data observations x (with the original coordinates in the lower dimensional space), instead of computing the coordinates of the data in a higher dimensional space.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Machine Learning] Interview Questions - Part 4</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-4/</link>
        <pubDate>Sun, 09 Oct 2022 22:31:17 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-4/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 9th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 9th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) Why are small convolution kernels such as 3x3 better than larger ones?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;First, you can use several smaller kernels to get the same receptive field and capture &lt;strong&gt;more spatial context&lt;/strong&gt; with &lt;strong&gt;less parameters and computations&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Secondly, because with smaller kernels, you will be using more filters. You&amp;rsquo;ll be able to use more activation functions and thus have a &lt;strong&gt;more discriminative mapping function being learnt&lt;/strong&gt; by your CNN.&lt;/p&gt;
&lt;p&gt;Also, small kernels would lead to &lt;strong&gt;slow reduction of image dimensions&lt;/strong&gt; making the network deep, whereas large kernels would decrease the size of the image really fast.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) The difference for dropout between training and testing&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Dropout is a simple way to prevent a neural network from &lt;strong&gt;overfitting&lt;/strong&gt; by making neurons output &amp;lsquo;wrong&amp;rsquo; values on purpose. It is a random process of disabling neurons in a layer with &lt;strong&gt;probability &lt;em&gt;p&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;At test time, however, we do not apply dropout with the test data. But that means your neurons will receive more connections and therefore more activations during inference than what they received during training. For example, if you use a dropout rate of 50% dropping two out of four neurons in a layer during training, the neurons in the next layer will receive twice the activations during inference and thus become overexcited. Accordingly, the values produced by these neurons will be too large by 50%. To correct this over-activation at inference time, you multiply the weights of the overexcited neurons by the &lt;strong&gt;retention probability (1 – &lt;em&gt;p&lt;/em&gt;)&lt;/strong&gt; to scale them down.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3) How does inference time vary with the depth of the decision tree?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Test time complexity would be &lt;strong&gt;O(depth)&lt;/strong&gt; since we have to move from root to a leaf node of the decision tree.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) With the increase of depth, what will be influnced in decison tree prediction?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More inference time&lt;/li&gt;
&lt;li&gt;To some degree, it reduces bias and prevent underfitting, but it may lead to overfitting (more leaf nodes).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5) Pros and Cons of decision tree&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Advantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Once the tree is constructed, the training data does not need to be stored. Instead, we can simply store &lt;strong&gt;splitting conditions&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Inference is very &lt;strong&gt;fast&lt;/strong&gt;, as test inputs simply need to traverse down the tree to a leaf.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No metrics&lt;/strong&gt; are needed, because the splits are based on feature thresholds.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Disavantages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Trees fail to deal with &lt;strong&gt;linear relationships&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Trees are quite &lt;strong&gt;unstable&lt;/strong&gt;. A few changes in the training dataset can create a completely different tree.&lt;/li&gt;
&lt;li&gt;The number of terminal nodes increases quickly with depth.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;6) What is the purpose of random restarts?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Random restart means restarting at a &lt;strong&gt;new random state&lt;/strong&gt; after a pre-defined
number of steps, which can turn a local search algorithm into an algorithm with &lt;strong&gt;global search capability&lt;/strong&gt;. It helps in &lt;strong&gt;non-convex optimization&lt;/strong&gt; to alleviate the problems of trapping in many local minima or flat regions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7) What is bias &amp;amp; variance decomposition?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The bias–variance decomposition is a way of analyzing a learning algorithm&amp;rsquo;s expected &lt;strong&gt;generalization error&lt;/strong&gt; with respect to a particular problem, which Bias-variance trade-off is quite significant to understand the errors and accuracies of &lt;strong&gt;supervised&lt;/strong&gt; machine learning algorithms.&lt;/p&gt;
&lt;p&gt;$$Generalization Error = Bias^2 + Variance + IrreducibleError$$&lt;/p&gt;
&lt;p&gt;, where the &lt;strong&gt;irreducible error&lt;/strong&gt; is caused by elements outside our control, such as statistical noise in the observations. No matter how good our model is, the data will have some noise or irreducible error that can not be removed.&lt;/p&gt;
&lt;p&gt;The formal explaination could be found &lt;a class=&#34;link&#34; href=&#34;https://allenkunle.me/bias-variance-decomposition&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;&lt;strong&gt;here&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8) Differences between gradient-boosting decision tree and random forest?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Differences cover the order of training process, the way to make predictions,&lt;/p&gt;
&lt;p&gt;A Random forest is a &lt;strong&gt;bagging&lt;/strong&gt; or &lt;strong&gt;bootstrap aggregating&lt;/strong&gt; method that builds decision trees &lt;strong&gt;independently&lt;/strong&gt; and &lt;strong&gt;parallelly&lt;/strong&gt; using different sub-samples for training. Subsequently, it uses &lt;strong&gt;majority vote&lt;/strong&gt; of weak learners to provide a final prediction. A Random forest can be used for both regression and classification problems. The rationale is that although a single tree may be inaccurate, the collective decisions of a bunch of trees are likely to be right most of the time. It&amp;rsquo;s the bagging, &lt;strong&gt;random feature selection&lt;/strong&gt;, averaging in random forests that reduce variance. However, it&amp;rsquo;s &lt;strong&gt;hard to interpret&lt;/strong&gt; since each classification decision or regression output has multiple decision paths.&lt;/p&gt;
&lt;p&gt;Gradient boosting decision tree uses the idea of &lt;strong&gt;boosting&lt;/strong&gt; is to build weak predictors &lt;strong&gt;sequentially&lt;/strong&gt; and use information of the previous built predictors to enhance performance of the model. Generally, gradient boosting can result in &lt;strong&gt;better performance&lt;/strong&gt; than random forests with proper parameters. However, gradient boosting may not be a good choice if you have a lot of noise, as it can result in &lt;strong&gt;overfitting&lt;/strong&gt;. They also tend to be &lt;strong&gt;harder to tune&lt;/strong&gt; than random forests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) What&amp;rsquo;s the range of cosine distance?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Cosine similarity finds the similarity between two points or vectors by calculating the angle between them. So, it will range from &lt;strong&gt;0 to 1&lt;/strong&gt;. When two points P1 &amp;amp; P2 are very near and lies on same axis to each other, cos_sim = 1; When two points P1 &amp;amp; P2 are far from each other and angle between points is 90 Degree, cos_sim = 0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) Differences between online training and offline training?&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Online ML&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Offline/Batch ML&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Complexity&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;More complex because the model keeps evolving over time.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Less complex because the model is fed with more consistent data sets periodically.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Computational power&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;More computational power because the continuous feed of data leads to continuous refinement.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Fewer computational power  because data is delivered in batches.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Use in production&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Harder to implement and control because the production model changes in real-time.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Easier to implement because offline learning provides engineers with more time to perfect the model before deployment.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Applications&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Weather, Stock Prices&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Big Data Software&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Machine Learning] Interview Questions - Part 3</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-3/</link>
        <pubDate>Sat, 08 Oct 2022 20:35:56 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-3/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 8th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 8th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) What’s the difference between Type I and Type II error?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Type I error is a &lt;strong&gt;false positive&lt;/strong&gt;, while Type II error is a &lt;strong&gt;false negative&lt;/strong&gt;. Briefly stated, Type I error means claiming something has happened when it hasn’t, while Type II error means that you claim nothing is happening when in fact something is.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) Generative model vs. Discriminative model&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A generative model cares how the data was generated in order to learn categories of data. (&lt;strong&gt;Estimate model, then define the classifier&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;A discriminative model will simply learn the &lt;strong&gt;distinction&lt;/strong&gt; between different categories of data. Discriminative models generally outperform generative models on classification tasks. (&lt;strong&gt;Directly define the classifier&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3) Instance-Based Learning vs. Model-Based Learning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Instance-based Learning: The system learns the examples by heart, then generalizes to new cases using a &lt;strong&gt;similarity&lt;/strong&gt; measure.&lt;/li&gt;
&lt;li&gt;Model-based Learning: The system generalizes from a set of examples by building a &lt;strong&gt;model&lt;/strong&gt; of these examples, then use that model to make predictions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;4) Label Encoding vs. One-Hot Encoding?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This question generally depends on your dataset and the model which you wish to apply.&lt;/p&gt;
&lt;p&gt;One-Hot Encoding simply creates &lt;strong&gt;additional features&lt;/strong&gt; based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature. We apply One-Hot Encoding when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The categorical feature is not ordinal.&lt;/li&gt;
&lt;li&gt;The number of categorical features is less so one-hot encoding can be effectively applied.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Label Encoding means each label is assigned a &lt;strong&gt;unique integer based on alphabetical ordering&lt;/strong&gt;. We apply Label Encoding when:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The categorical feature is ordinal.&lt;/li&gt;
&lt;li&gt;The number of categories is quite large, which may lead to high memory consumption.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;5) LDA vs. PCA for dimensionality reduction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Both LDA and PCA are &lt;strong&gt;linear transformation&lt;/strong&gt; techniques: LDA is a &lt;strong&gt;supervised&lt;/strong&gt; whereas PCA is &lt;strong&gt;unsupervised&lt;/strong&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PCA tries to maximize the data&amp;rsquo;s variability while reducing the dataset&amp;rsquo;s dimensionality.&lt;/li&gt;
&lt;li&gt;LDA finds the linear discriminants in order to maximize the variance between the different classes while minimizing the variance within the class.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;6) How does Content-based image retrieval work?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CBIR is the concept of using images to gather metadata on their content. Compared to the current image retrieval approach based on the keywords associated to the images, this technique generates its &lt;strong&gt;metadata&lt;/strong&gt; from computer vision techniques to extract the relevant informations that will be used for &lt;strong&gt;queries&lt;/strong&gt;. Many approach are possible from feature detection to retrieve keywords to the usage of CNN to extract &lt;strong&gt;dense features&lt;/strong&gt; that will be associated to &lt;strong&gt;a known distribution of keywords&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We care less about what is shown on the image but more about the similarity between the metadata generated by a known image and a list of known labels projected into this metadata space.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7)  Why do we use convolutions for images rather than just FC layers?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Firstly, convolutions preserve, encode, and actually use the &lt;strong&gt;spatial information&lt;/strong&gt; from the image. If we used only FC layers we would have no relative spatial information.&lt;/p&gt;
&lt;p&gt;Secondly, CNNs have a partially built-in &lt;strong&gt;translation in-variance&lt;/strong&gt;, since we&amp;rsquo;re going to apply the convolution in a sliding window fashion across the entire image anyways.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8) Why do we have max-pooling in classification CNNs?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Max-pooling in a CNN allows you to &lt;strong&gt;reduce computation&lt;/strong&gt; since your feature maps are smaller after the pooling. You don&amp;rsquo;t lose too much semantic information since you&amp;rsquo;re taking the maximum activation. There&amp;rsquo;s also a theory that max-pooling contributes a bit to giving CNNs more &lt;strong&gt;translation in-variance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) What is the significance of Residual Networks?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The skip connections in ResNet solve the problem of vanishing gradient in deep neural networks by allowing for &lt;strong&gt;direct feature access from previous layers&lt;/strong&gt;. The other way that these connections help is by allowing the model to learn the identity functions which ensures that the &lt;strong&gt;higher layer will perform at least as good as the lower layer&lt;/strong&gt;, and not worse.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) What is batch normalization?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Training Deep Neural Networks is complicated by the fact that &lt;strong&gt;the distribution of each layer&amp;rsquo;s inputs changes&lt;/strong&gt; during training, as the parameters of the previous layers change. A network is just a series of layers, where &lt;strong&gt;the output of one layer becomes the input to the next&lt;/strong&gt;. The idea is then to normalize the inputs of each layer in such a way that they have &lt;strong&gt;a mean output activation of 0&lt;/strong&gt; and &lt;strong&gt;standard deviation of 1&lt;/strong&gt;. This is analogous to how the inputs to networks are standardized.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Machine Learning] Interview Questions - Part 2</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-2/</link>
        <pubDate>Fri, 07 Oct 2022 17:05:02 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-2/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 7th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 7th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) Why do ensembles typically have higher scores than individual models?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An ensemble is the combination of &lt;strong&gt;multiple models&lt;/strong&gt; to create a &lt;strong&gt;single prediction&lt;/strong&gt;. The key idea is that the errors of one model will be compensated by the right predictions of the other models and thus the score of the ensemble will be higher.&lt;/p&gt;
&lt;p&gt;We need diverse models for creating an ensemble.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using different ML algorithms.&lt;/li&gt;
&lt;li&gt;Using different subsets of the data for training. (Bagging)&lt;/li&gt;
&lt;li&gt;Giving a different weight to each of the samples of the training set. (Boosting)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Engineers need to find a balance between &lt;strong&gt;execution time&lt;/strong&gt; and &lt;strong&gt;accuracy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) What is an imbalanced dataset? Can you list some ways to deal with it?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An imbalanced dataset has different proportions of categories. There are different options to deal with imbalanced datasets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resampling the dataset: undersampling majority classes and oversampling minority classes&lt;/li&gt;
&lt;li&gt;Data Augmentation&lt;/li&gt;
&lt;li&gt;Cross Validation&lt;/li&gt;
&lt;li&gt;Choose a right algorithm, e.g., random forest&lt;/li&gt;
&lt;li&gt;Using appropriate metrics, e.g., F-score, Confusion Matrix, which describe the performance of the model better on an imbalanced dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3) What is data augmentation? Can you give some examples?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data augmentation is a technique for generating new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) Explain how the AUC - ROC curve works&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;ROC or Receiver Operating Characteristic curve represents a graphical representation of the contrast between &lt;strong&gt;true positive rates and the false positive rate&lt;/strong&gt; at various thresholds.&lt;/p&gt;
&lt;p&gt;AUC is known for Area Under the ROC curve. It calculates the two-dimensional area under the entire ROC curve ranging from 0 to 1, which means an excellent model will have AUC near 1, and hence it will show a good measure of &lt;strong&gt;separability&lt;/strong&gt;. AUC is &lt;strong&gt;scale-invariant&lt;/strong&gt;. It measures &lt;strong&gt;how well predictions are ranked&lt;/strong&gt;, rather than their absolute values. AUC is &lt;strong&gt;classification-threshold-invariant&lt;/strong&gt;. It measures the quality of the model&amp;rsquo;s predictions irrespective of what classification threshold is chosen.&lt;/p&gt;
&lt;p&gt;AUC is not preferable when we need to calibrate probability output. Further, AUC is not a useful metric when there are wide disparities in the cost of false negatives vs false positives, and it is difficult to minimize one type of classification error. For example, when doing email spam detection, you likely want to prioritize minimizing false positives even if that results in a significant increase of false negatives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5) What is Precision/Recall/F1-score?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Precision (positive predictive value) is the fraction of relevant instances among the retrieved instances.&lt;/p&gt;
&lt;p&gt;$$ Precision = \frac{TP}{TP + FP} $$&lt;/p&gt;
&lt;p&gt;Recall (sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.&lt;/p&gt;
&lt;p&gt;$$ Recall = \frac{TP}{TP + FN} $$&lt;/p&gt;
&lt;p&gt;F1-score is the weighted average of precision and recall. It considers both false positive and false negative into account.&lt;/p&gt;
&lt;p&gt;$$ F1 = \frac{2PR}{P + R} $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6) Define Learning Rate&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The learning rate is a hyper-parameter used to govern the pace at which an algorithm updates or learns the values of a parameter estimate. In other words, it controls how much we are adjusting the weights of our network with respect the loss gradient.&lt;/p&gt;
&lt;p&gt;When training loss fluctuates, we may reduce the learning rate. Otherwise, SGD jumps too far and misses the area near local minima.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7) The differences between Batch Gradient Descent and Stochastic Gradient Descent&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Batch Gradient Descent involves calculations over the &lt;strong&gt;whole training set&lt;/strong&gt; at each step as a result of which it is very slow on very large training data. Thus, it becomes very &lt;strong&gt;computationally expensive&lt;/strong&gt;. However, this is great for &lt;strong&gt;convex&lt;/strong&gt; or relatively smooth error manifolds. Also, Batch GD scales well with the number of features.&lt;/p&gt;
&lt;p&gt;Stochastic gradient descent (SGD) picks up a &lt;strong&gt;&amp;ldquo;random&amp;rdquo; instance&lt;/strong&gt; of training data at each step and then computes the gradient, making it much faster to reach the &lt;strong&gt;convergence&lt;/strong&gt;. Also, it can &lt;strong&gt;escape shallow local minima&lt;/strong&gt; more easily. There tends to be more noise, which allows for &lt;strong&gt;improving generalization error&lt;/strong&gt;. However, it might lead to result in &lt;strong&gt;larger variance&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Batch GD: Batch size = Size of training set&lt;br&gt;
Stochastic GD: Batch size = 1&lt;br&gt;
Mini-Batch GD: 1 &amp;lt; Batch size &amp;lt; Size of training set&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8) Epoch vs. Batch vs. Iteration&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Epoch: It&amp;rsquo;s the number of times the whole training dataset is passed through the model. &lt;br&gt;
Batch: It&amp;rsquo;s the number of examples processed together in one pass.&lt;br&gt;
Iteration: It&amp;rsquo;s the number of batches required to complete one epoch.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) What is gradient vanishing? What is gradient explosion?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;As we add more and more hidden layers, &lt;strong&gt;backpropagation&lt;/strong&gt; becomes less and less useful in passing information to the lower layers. The error may be so small by the time it reaches layers close to the input of the model. In effect, as information is passed back, the gradients begin to vanish and become small relative to the weights of the networks. On the contrary, if the gradients get larger or even NaN as our backpropagation progresses, &lt;strong&gt;the error gradients accumulate&lt;/strong&gt; and end up with exploding gradients having big weight updates.&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;sigmoid&lt;/strong&gt;, it saturates at zero for large negative values and at one for large positive values. The same applies to the &lt;strong&gt;Tanh&lt;/strong&gt; function that saturates at -1 and 1. &lt;strong&gt;ReLU&lt;/strong&gt; returns the input if the input value is positive, and it returns 0 if the input is negative.&lt;/p&gt;
&lt;p&gt;ReLu can solve gradient vanishing but may cause gradient explosion. &lt;strong&gt;The output of ReLU is unbounded in the positive domain by design.&lt;/strong&gt; This means that the output can, in some situations, continue to grow in size.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) What&amp;rsquo;s the difference between boosting and bagging?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Boosting and bagging are similar, in that they are both ensembling techniques, where &lt;strong&gt;multiple weak learners&lt;/strong&gt; (classifiers/regressors that are barely better than guessing) combine (through averaging or max vote) to form &lt;strong&gt;a single strong learner&lt;/strong&gt; that can make accurate predictions.&lt;/p&gt;
&lt;p&gt;Bagging means that you take &lt;strong&gt;bootstrap&lt;/strong&gt; samples (with replacement) of your dataset and each sample trains a (potentially) weak learner. Boosting, on the other hand, uses all data to train each learner, but instances that were misclassified by the previous learners are given &lt;strong&gt;more weight&lt;/strong&gt; so that &lt;strong&gt;subsequent&lt;/strong&gt; learners give more focus to them during training.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Machine Learning] Interview Questions - Part 1</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-1/</link>
        <pubDate>Sat, 01 Oct 2022 19:51:42 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-1/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 1st, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 1st, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) Explain bias and variance, and trade-off between them&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Bias is the &lt;strong&gt;difference&lt;/strong&gt; between the average prediction of our model and the ground truth.&lt;/p&gt;
&lt;p&gt;Variance refers to the &lt;strong&gt;variability&lt;/strong&gt; in the model prediction. In other words, it reflects the changes in the model when using different portions of the training dataset.&lt;/p&gt;
&lt;p&gt;Bias and variance are &lt;strong&gt;inversely connected&lt;/strong&gt;. An underfitting model has high bias and low variance, while an overfitting model has high variance and low bias. So we need to find the right balance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) What is gradient descent?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;GD is an &lt;strong&gt;optimization&lt;/strong&gt; algorithm that finds the values of parameters (coefficients) of a loss function that minimizes a cost function.&lt;/p&gt;
&lt;p&gt;GD is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3) Difference between Loss Function, Cost Function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The Loss function is associated with &lt;strong&gt;single training example&lt;/strong&gt;, and the cost function is the average value of the loss function over the &lt;strong&gt;entire training dataset&lt;/strong&gt;. In ML, we usually try to optimize our cost
function rather than loss function.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) How to handle overfitting and underfitting&lt;/strong&gt; &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Handling Overfitting&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Handling Underfitting&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;More Training Data&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Removing Data Noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Regularization&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Regularization&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Iterations&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Iterations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Features&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Features&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Learning Rate&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Learning Rate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Other Strategies: Pruning, Dropout, etc.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Model Complexity&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;5) What is curse of dimensionality? How to prevent it?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CoD basically means that the error increases with the increase in the number of features. It leads to exponential increase in computational efforts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improving the ratio of observations over attributes&lt;/li&gt;
&lt;li&gt;Making distances in feature space more meaningful&lt;/li&gt;
&lt;li&gt;Removing features that have no correlation with the target distribution&lt;/li&gt;
&lt;li&gt;Removing or combining features that have redundant correlation with target distribution&lt;/li&gt;
&lt;li&gt;Extracting new features with a more direct correlation with target distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;6) What is regularization, and give some examples of common methods?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Regularization refers to techniques that are used to calibrate machine learning models so as to &lt;strong&gt;avoid the risk of overfitting&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The obvious disadvantage of ridge is model interpretability. It will shrink the coefficients for least important features, &lt;strong&gt;only close to zero&lt;/strong&gt;. However, for lasso, it can force some of the coefficient estimates to &lt;strong&gt;be zero&lt;/strong&gt; when the weight is sufficiently large. Therefore, the lasso method also performs variable selection and is said to yield sparse models.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;L1 norm (Lasso)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;L2 norm (Ridge)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Penalizes the sum of absolute values of weights&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Penalizes the sum of squares of weights&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Sparse solution&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Non-sparse solution&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Feature selection&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;No feature selection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Robust to outliers&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Not robust to outliers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Unable to learn complex data patterns&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Able to learn complex data patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;7) Explain Principal Component Analysis (PCA)?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;PCA is used for the &lt;strong&gt;dimensionality reduction&lt;/strong&gt;, which tries to find the lower-dimensional surface to project the high-dimensional data.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://builtin.com/data-science/step-step-explanation-principal-component-analysis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Common Steps&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standardizing the range of continuous initial variables&lt;/li&gt;
&lt;li&gt;Computing the covariance matrix to identify correlations&lt;/li&gt;
&lt;li&gt;Computing the eigenvectors and eigenvalues of the covariance matrix to identify the principal components&lt;/li&gt;
&lt;li&gt;Creating a feature vector to decide which principal components to keep&lt;/li&gt;
&lt;li&gt;Recasting the data along the principal components axes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;8) What is data normalization and why do we need it?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Data normalization is a &lt;strong&gt;preprocessing&lt;/strong&gt; step to &lt;strong&gt;re-scale values&lt;/strong&gt; to fit in a specific range to assure better convergence. In general, it boils down to subtracting the &lt;strong&gt;mean&lt;/strong&gt; of each data point and dividing by its &lt;strong&gt;standard deviation&lt;/strong&gt;. The data normalization makes all features weighted equally. Otherwise, some features with high magnitude will be weighted more in the cost function, while other features with lower values will be allocated less weights.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) What is the difference between training, validation set and test set?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The training dataset is used for &lt;strong&gt;fitting the model’s parameters&lt;/strong&gt;. However, the accuracy that we achieve on the training set is not reliable for predicting if the model will be accurate on new samples.&lt;/p&gt;
&lt;p&gt;The validation dataset is used to &lt;strong&gt;measure how well the model does&lt;/strong&gt; on examples that weren’t part of the training dataset and to &lt;strong&gt;provide information&lt;/strong&gt; for adjusting the model. The more evaluations, the more information is leaked. So we can end up overfitting to the validation data.&lt;/p&gt;
&lt;p&gt;The test dataset is used to measure how well the model does on previously unseen examples. It should &lt;strong&gt;only be used once&lt;/strong&gt; we have tuned the parameters using the validation set.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) What is cross-validation?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;CV is a statistical &lt;strong&gt;resampling&lt;/strong&gt; technique that uses different parts of the dataset to train and test an ML algorithm on different iterations. The aim of CV provides the ability to estimate model performance on unseen data.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Career Talk] SDE or DS, How Can I Choose?</title>
        <link>https://tonyfpy.github.io/p/career-talk-sde-or-ds-how-can-i-choose/</link>
        <pubDate>Tue, 26 Apr 2022 22:57:49 +0800</pubDate>
        
        <guid>https://tonyfpy.github.io/p/career-talk-sde-or-ds-how-can-i-choose/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on April 26th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on April 28th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;Recently, I am preparing for the application of 2023 summer intership in US. Since it might be my last industrial internship, this experience would influence my career path to a large extent and pave the way to my future career development. It&amp;rsquo;s time to conisder it comprehensively.&lt;/p&gt;
&lt;p&gt;I would like to consider myself as a freshman in job hunting, because it&amp;rsquo;s my first time to seek employment in another country. In order to find a desirable job placement, I&amp;rsquo;ve gone through many related materials online. In this post, I&amp;rsquo;m gonna talk about &lt;strong&gt;Software Devlopment(SD)&lt;/strong&gt; and &lt;strong&gt;Data Science(DS)&lt;/strong&gt;, two popular job directions most CS graduates will choose.&lt;/p&gt;
&lt;h2 id=&#34;sd-vs-ds&#34;&gt;SD V.S. DS&lt;/h2&gt;
&lt;h3 id=&#34;number-of-job-opportunities&#34;&gt;Number of Job Opportunities&lt;/h3&gt;
&lt;p&gt;In general, companies offers more job positions for SD than DS evidently. The ratio is about &lt;strong&gt;10 : 1&lt;/strong&gt; in average. SD is &lt;strong&gt;more friendly to new graduates&lt;/strong&gt; than DS in that companies provides more SD placements for them. DS requires the candidates to earn a high education degree or have past working experience.&lt;/p&gt;
&lt;h3 id=&#34;job-categories&#34;&gt;Job Categories&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;SD&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software Development Engineer&lt;/li&gt;
&lt;li&gt;Application Developer&lt;/li&gt;
&lt;li&gt;Full-stack Web Developer&lt;/li&gt;
&lt;li&gt;Frontend Developer&lt;/li&gt;
&lt;li&gt;Backend Developer&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DS&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Scientist&lt;/li&gt;
&lt;li&gt;Applied Scientist&lt;/li&gt;
&lt;li&gt;Statistician&lt;/li&gt;
&lt;li&gt;Business Intelligence Engineer&lt;/li&gt;
&lt;li&gt;Data/Product/Business Analyst&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cross Domain&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning Engineer&lt;/li&gt;
&lt;li&gt;Deep Learning Engineer&lt;/li&gt;
&lt;li&gt;Data Engineer&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;salary&#34;&gt;Salary&lt;/h3&gt;
&lt;p&gt;The salary may vary depending on your experience, skills, training, certifications and your employer. In general, SD-related professionals are paid higher than DS-related professionals. Reasearch-oriented DS jobs have higher salaries than other kinds of DS jobs, because they are usually demanding and only open for PhDs.&lt;/p&gt;
&lt;h3 id=&#34;degree-requirements&#34;&gt;Degree Requirements&lt;/h3&gt;
&lt;p&gt;SD: Bachlor&amp;rsquo;s degree or higher &lt;br/&gt;
DS: Master&amp;rsquo;s degree or higher. Many positions even require a Doctoral degree. &lt;br/&gt;&lt;/p&gt;
&lt;h3 id=&#34;hard-skills&#34;&gt;Hard Skills&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;SD&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Algorithm and Data Structure&lt;/li&gt;
&lt;li&gt;Programming Paradigms&lt;/li&gt;
&lt;li&gt;System Design&lt;/li&gt;
&lt;li&gt;Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DS&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Statistics and Machien Learning&lt;/li&gt;
&lt;li&gt;Data Manipulation and Modeling&lt;/li&gt;
&lt;li&gt;Data Visualization&lt;/li&gt;
&lt;li&gt;Experiemnts Design and Analysis&lt;/li&gt;
&lt;li&gt;Business Case&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;soft-skills&#34;&gt;Soft Skills&lt;/h3&gt;
&lt;p&gt;Common soft skills are indispensable for SD and DS in your long-term career development.&lt;/p&gt;
&lt;p&gt;Besides, DS requires the candidates to have &lt;strong&gt;strong communications skills&lt;/strong&gt;, &lt;strong&gt;data-driven decision making&lt;/strong&gt;, &lt;strong&gt;product sense&lt;/strong&gt;, etc.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;job-descriptions&#34;&gt;Job Descriptions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Job responsibilities vary based on employers&amp;rsquo; requirements and should be learned case by case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;sd&#34;&gt;SD&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Full-Stack Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Front-End + Back-End&lt;/li&gt;
&lt;li&gt;UI + Server + Database Configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile App Developer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Android / IOS&lt;/li&gt;
&lt;li&gt;Memory + Computational Power&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Graphics Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;2D and 3D Digital Platforms for Gaming and Video Production&lt;/li&gt;
&lt;li&gt;Math + CS&lt;/li&gt;
&lt;li&gt;Unity, OpenGL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embedded Systems Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Control of machines&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software Development Engineer in Test(SDET)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Dev + Automated Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DevOps Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Dev + Operations + Deployment&lt;/li&gt;
&lt;li&gt;Network or Sys Admin&lt;/li&gt;
&lt;li&gt;Source Control / Infrastructure Automation / Cloud&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ds&#34;&gt;DS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Analysts&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Datasets -&amp;gt; Analysis -&amp;gt; Visulization(Reports / Resentations / &amp;hellip;)&lt;/li&gt;
&lt;li&gt;Experiment (A/B testing) + Statistic + SQL / R / Python&lt;/li&gt;
&lt;li&gt;Product Interpretation + Actionable Insights + Communication&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Scientist&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Data Manipulation + Statistical Modeling + Machine Learning&lt;/li&gt;
&lt;li&gt;Product Improvement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Applied Scientist / Research Scientist&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Independent Research + Literature Review&lt;/li&gt;
&lt;li&gt;Model Design + Implementation + Optimization&lt;/li&gt;
&lt;li&gt;Long-term Research&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quant Researcher&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Finance + Statistics + Coding&lt;/li&gt;
&lt;li&gt;Time Series&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cross-domain&#34;&gt;Cross Domain&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Data Pipeline&lt;/li&gt;
&lt;li&gt;Data Infrastructure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Learning Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Mathematics + Statistics + Probability&lt;/li&gt;
&lt;li&gt;Data Modeling and Evaluation&lt;/li&gt;
&lt;li&gt;ML System Design&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;www.xiaogeedu.com&#34; &gt;SDE and DS 的求职难度和就业现状&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ph-education.com/%e7%95%99%e5%ad%a6%e7%94%b3%e8%af%b7/%e5%b9%b2%e8%b4%a7%e7%bb%8f%e9%aa%8c%e5%90%88%e9%9b%86/%e5%b9%b2%e8%b4%a7-%e4%b8%80%e4%b8%aa%e5%85%b8%e5%9e%8b%e5%8c%97%e7%be%8eds-master%e7%9a%84%e6%b1%82%e8%81%8c%e5%85%a8%e8%bf%87%e7%a8%8b%e5%9b%9e%e9%a1%be/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一个典型北美DS master的求职全过程回顾&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Sf4y1p79r?spm_id_from=333.880.my_history.page.click&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;疫情下我是如何拿到FB DS offer 的？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.coursera.org/introduction-data-science-careers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;An introduction to data science careers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://intellipaat.com/blog/data-science-vs-software-engineering/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data Science vs Software Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dataapplab.com/differences-between-ds-da-ba-and-de-and-key-points-of-job-interview/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据岗位大合集｜DS、DA、BA和DE的区别及求职面试重点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.1point3acres.com/bbs/thread-850531-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;你为什么不该选择DS - 可能是2022年最详细的劝退贴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.1point3acres.com/bbs/thread-601652-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data Science相关岗位全面解析(DS vs DA vs MLE vs DE)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.1point3acres.com/bbs/thread-885801-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DS找工回顾及资料总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://analyticsindiamag.com/a-complete-guide-to-data-science-career-path-by-great-learning-aim/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A Complete Guide To Data Science Career Path – By Great Learning &amp;amp; AIM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.thinkful.com/blog/software-engineer-career-path/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Software Engineer Career Path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.geeksforgeeks.org/career-paths-for-software-developers-and-programmers-in-2019/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Career Paths For Software Developers and Programmers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
