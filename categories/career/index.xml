<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Career on Tony Feng</title>
        <link>https://tonyfpy.github.io/categories/career/</link>
        <description>Recent content in Career on Tony Feng</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language><atom:link href="https://tonyfpy.github.io/categories/career/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[Machine Learning] Interview Questions - Part 2</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-2/</link>
        <pubDate>Fri, 07 Oct 2022 17:05:02 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-2/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 1st, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 1st, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) Why do ensembles typically have higher scores than individual models?&lt;/strong&gt;&lt;br&gt;
An ensemble is the combination of &lt;strong&gt;multiple models&lt;/strong&gt; to create a &lt;strong&gt;single prediction&lt;/strong&gt;. The key idea is that the errors of one model will be compensated by the right predictions of the other models and thus the score of the ensemble will be higher.&lt;/p&gt;
&lt;p&gt;We need diverse models for creating an ensemble.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Using different ML algorithms.&lt;/li&gt;
&lt;li&gt;Using different subsets of the data for training. (Bagging)&lt;/li&gt;
&lt;li&gt;Giving a different weight to each of the samples of the training set. (Boosting)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Engineers need to find a balance between &lt;strong&gt;execution time&lt;/strong&gt; and &lt;strong&gt;accuracy&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) What is an imbalanced dataset? Can you list some ways to deal with it?&lt;/strong&gt;&lt;br&gt;
An imbalanced dataset has different proportions of categories. There are different options to deal with imbalanced datasets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Resampling the dataset: undersampling majority classes and oversampling minority classes&lt;/li&gt;
&lt;li&gt;Data Augmentation&lt;/li&gt;
&lt;li&gt;Cross Validation&lt;/li&gt;
&lt;li&gt;Choose a right algorithm, e.g., random forest&lt;/li&gt;
&lt;li&gt;Using appropriate metrics, e.g., F-score, Confusion Matrix, which describe the performance of the model better on an imbalanced dataset.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3) What is data augmentation? Can you give some examples?&lt;/strong&gt;&lt;br&gt;
Data augmentation is a technique for generating new data by modifying existing data in such a way that the target is not changed, or it is changed in a known way.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) Explain how the AUC - ROC curve works&lt;/strong&gt;&lt;br&gt;
ROC or Receiver Operating Characteristic curve represents a graphical representation of the contrast between &lt;strong&gt;true positive rates and the false positive rate&lt;/strong&gt; at various thresholds.&lt;/p&gt;
&lt;p&gt;AUC is known for Area Under the ROC curve. It calculates the two-dimensional area under the entire ROC curve ranging from 0 to 1, which means an excellent model will have AUC near 1, and hence it will show a good measure of &lt;strong&gt;separability&lt;/strong&gt;. AUC is &lt;strong&gt;scale-invariant&lt;/strong&gt;. It measures &lt;strong&gt;how well predictions are ranked&lt;/strong&gt;, rather than their absolute values. AUC is &lt;strong&gt;classification-threshold-invariant&lt;/strong&gt;. It measures the quality of the model&amp;rsquo;s predictions irrespective of what classification threshold is chosen.&lt;/p&gt;
&lt;p&gt;AUC is not preferable when we need to calibrate probability output. Further, AUC is not a useful metric when there are wide disparities in the cost of false negatives vs false positives, and it is difficult to minimize one type of classification error. For example, when doing email spam detection, you likely want to prioritize minimizing false positives even if that results in a significant increase of false negatives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5) What is Precision/Recall/F1-score?&lt;/strong&gt;&lt;br&gt;
Precision (positive predictive value) is the fraction of relevant instances among the retrieved instances.&lt;/p&gt;
&lt;p&gt;$$ Precision = \frac{TP}{TP + FP} $$&lt;/p&gt;
&lt;p&gt;Recall (sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances.&lt;/p&gt;
&lt;p&gt;$$ Recall = \frac{TP}{TP + FN} $$&lt;/p&gt;
&lt;p&gt;F1-score is the weighted average of precision and recall. It considers both false positive and false negative into account.&lt;/p&gt;
&lt;p&gt;$$ F1 = \frac{2PR}{P + R} $$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6) Define Learning Rate&lt;/strong&gt;&lt;br&gt;
The learning rate is a hyper-parameter used to govern the pace at which an algorithm updates or learns the values of a parameter estimate. In other words, it controls how much we are adjusting the weights of our network with respect the loss gradient.&lt;/p&gt;
&lt;p&gt;When training loss fluctuates, we may reduce the learning rate. Otherwise, SGD jumps too far and misses the area near local minima.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;7) The differences between Batch Gradient Descent and Stochastic Gradient Descent&lt;/strong&gt;&lt;br&gt;
Batch Gradient Descent involves calculations over the &lt;strong&gt;whole training set&lt;/strong&gt; at each step as a result of which it is very slow on very large training data. Thus, it becomes very &lt;strong&gt;computationally expensive&lt;/strong&gt;. However, this is great for &lt;strong&gt;convex&lt;/strong&gt; or relatively smooth error manifolds. Also, Batch GD scales well with the number of features.&lt;/p&gt;
&lt;p&gt;Stochastic gradient descent (SGD) picks up a &lt;strong&gt;&amp;ldquo;random&amp;rdquo; instance&lt;/strong&gt; of training data at each step and then computes the gradient, making it much faster to reach the &lt;strong&gt;convergence&lt;/strong&gt;. Also, it can &lt;strong&gt;escape shallow local minima&lt;/strong&gt; more easily.&lt;/p&gt;
&lt;p&gt;Batch GD: Batch size = Size of training set&lt;br&gt;
Stochastic GD: Batch size = 1&lt;br&gt;
Mini-Batch GD: 1 &amp;lt; Batch size &amp;lt; Size of training set&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;8) Epoch vs. Batch vs. Iteration&lt;/strong&gt;&lt;br&gt;
Epoch: It&amp;rsquo;s the number of times the whole training dataset is passed through the model. &lt;br&gt;
Batch: It&amp;rsquo;s the number of examples processed together in one pass.&lt;br&gt;
Iteration: It&amp;rsquo;s the number of batches required to complete one epoch.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) What is gradient vanishing? What is gradient explosion?&lt;/strong&gt;&lt;br&gt;
As we add more and more hidden layers, back propagation becomes less and less useful in passing information to the lower layers. &lt;strong&gt;A large change in the input will cause a small change in the output.&lt;/strong&gt; In effect, as information is passed back, the gradients begin to vanish and become small relative to the weights of the networks. On the contrary, if the gradients get larger or even NaN as our backpropagation progresses, &lt;strong&gt;the error gradients accumulate&lt;/strong&gt; and end up with exploding gradients having big weight updates.&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;sigmoid&lt;/strong&gt;, it saturates at zero for large negative values and at one for large positive values. The same applies to the &lt;strong&gt;Tanh&lt;/strong&gt; function that saturates at -1 and 1. &lt;strong&gt;ReLU&lt;/strong&gt; returns the input if the input value is positive, and it returns 0 if the input is negative.&lt;/p&gt;
&lt;p&gt;ReLu can solve gradient vanishing but may cause gradient explosion. &lt;strong&gt;The output of ReLU is unbounded in the positive domain by design.&lt;/strong&gt; This means that the output can, in some situations, continue to grow in size.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) What&amp;rsquo;s the difference between boosting and bagging?&lt;/strong&gt;&lt;br&gt;
Boosting and bagging are similar, in that they are both ensembling techniques, where &lt;strong&gt;multiple weak learners&lt;/strong&gt; (classifiers/regressors that are barely better than guessing) combine (through averaging or max vote) to form &lt;strong&gt;a single strong learner&lt;/strong&gt; that can make accurate predictions.&lt;/p&gt;
&lt;p&gt;Bagging means that you take &lt;strong&gt;bootstrap&lt;/strong&gt; samples (with replacement) of your dataset and each sample trains a (potentially) weak learner. Boosting, on the other hand, uses all data to train each learner, but instances that were misclassified by the previous learners are given &lt;strong&gt;more weight&lt;/strong&gt; so that &lt;strong&gt;subsequent&lt;/strong&gt; learners give more focus to them during training.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Machine Learning] Interview Questions - Part 1</title>
        <link>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-1/</link>
        <pubDate>Sat, 01 Oct 2022 19:51:42 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/machine-learning-interview-questions-part-1/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 1st, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 1st, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;The post contains a collection of questions for machine learning interview.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;questions&#34;&gt;Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;1) Explain bias and variance, and trade-off between them&lt;/strong&gt;&lt;br&gt;
Bias is the &lt;strong&gt;difference&lt;/strong&gt; between the average prediction of our model and the ground truth.&lt;/p&gt;
&lt;p&gt;Variance refers to the &lt;strong&gt;variability&lt;/strong&gt; in the model prediction. In other words, it reflects the changes in the model when using different portions of the training dataset.&lt;/p&gt;
&lt;p&gt;Bias and variance are &lt;strong&gt;inversely connected&lt;/strong&gt;. An underfitting model has high bias and low variance, while an overfitting model has high variance and low bias. So we need to find the right balance.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2) What is gradient descent?&lt;/strong&gt;&lt;br&gt;
GD is an &lt;strong&gt;optimization&lt;/strong&gt; algorithm that finds the values of parameters (coefficients) of a loss function that minimizes a cost function.&lt;/p&gt;
&lt;p&gt;GD is best used when the parameters cannot be calculated analytically (e.g. using linear algebra) and must be searched for by an optimization algorithm.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3) Difference between Loss Function, Cost Function&lt;/strong&gt;&lt;br&gt;
The Loss function is associated with &lt;strong&gt;single training example&lt;/strong&gt;, and the cost function is the average value of the loss function over the &lt;strong&gt;entire training dataset&lt;/strong&gt;. In ML, we usually try to optimize our cost
function rather than loss function.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4) How to handle overfitting and underfitting&lt;/strong&gt; &lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Handling Overfitting&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Handling Underfitting&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;More Training Data&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Removing Data Noise&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Regularization&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Regularization&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Iterations&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Iterations&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Features&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Features&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Learning Rate&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Reducing Learning Rate&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Other Strategies: Pruning, Dropout, etc.&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Increasing Model Complexity&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;5) What is curse of dimensionality? How to prevent it?&lt;/strong&gt;&lt;br&gt;
CoD basically means that the error increases with the increase in the number of features. It leads to exponential increase in computational efforts.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Improving the ratio of observations over attributes&lt;/li&gt;
&lt;li&gt;Making distances in feature space more meaningful&lt;/li&gt;
&lt;li&gt;Removing features that have no correlation with the target distribution&lt;/li&gt;
&lt;li&gt;Removing or combining features that have redundant correlation with target distribution&lt;/li&gt;
&lt;li&gt;Extracting new features with a more direct correlation with target distribution&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;6) What is regularization, and give some examples of common methods?&lt;/strong&gt;&lt;br&gt;
Regularization refers to techniques that are used to calibrate machine learning models so as to &lt;strong&gt;avoid the risk of overfitting&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The obvious disadvantage of ridge is model interpretability. It will shrink the coefficients for least important features, &lt;strong&gt;only close to zero&lt;/strong&gt;. However, for lasso, it can force some of the coefficient estimates to &lt;strong&gt;be zero&lt;/strong&gt; when the weight is sufficiently large. Therefore, the lasso method also performs variable selection and is said to yield sparse models.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;L1 norm (Lasso)&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;L2 norm (Ridge)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Penalizes the sum of absolute values of weights&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Penalizeshe the sum of squares of weights&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Sparse solution&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Non-sparse solution&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Feature selection&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;No feature selection&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Robust to outliers&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Not robust to outliers&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Unable to learn complex data patterns&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Able to learn complex data patterns&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;7) Explain Principal Component Analysis (PCA)?&lt;/strong&gt;&lt;br&gt;
PCA is used for the &lt;strong&gt;dimensionality reduction&lt;/strong&gt;, which tries to find the lower-dimensional surface to project the high-dimensional data.&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://builtin.com/data-science/step-step-explanation-principal-component-analysis&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Common Steps&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Standardizing the range of continuous initial variables&lt;/li&gt;
&lt;li&gt;Computing the covariance matrix to identify correlations&lt;/li&gt;
&lt;li&gt;Computing the eigenvectors and eigenvalues of the covariance matrix to identify the principal components&lt;/li&gt;
&lt;li&gt;Creating a feature vector to decide which principal components to keep&lt;/li&gt;
&lt;li&gt;Recasting the data along the principal components axes&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;8) What is data normalization and why do we need it?&lt;/strong&gt;&lt;br&gt;
Data normalization is a &lt;strong&gt;preprocessing&lt;/strong&gt; step to &lt;strong&gt;re-scale values&lt;/strong&gt; to fit in a specific range to assure better convergence. In general, it boils down to subtracting the &lt;strong&gt;mean&lt;/strong&gt; of each data point and dividing by its &lt;strong&gt;standard deviation&lt;/strong&gt;. The data normalization makes all features weighted equally. Otherwise, some features with high magnitude will be weighted more in the cost function, while other features with lower values will be allocated less weights.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;9) What is the difference between training, validation set and test set?&lt;/strong&gt;&lt;br&gt;
The training dataset is used for &lt;strong&gt;fitting the model’s parameters&lt;/strong&gt;. However, the accuracy that we achieve on the training set is not reliable for predicting if the model will be accurate on new samples.&lt;/p&gt;
&lt;p&gt;The validation dataset is used to &lt;strong&gt;measure how well the model does&lt;/strong&gt; on examples that weren’t part of the training dataset and to &lt;strong&gt;provide information&lt;/strong&gt; for adjusting the model. The more evaluations, the more information is leaked. So we can end up overfitting to the validation data.&lt;/p&gt;
&lt;p&gt;The test dataset is used to measure how well the model does on previously unseen examples. It should &lt;strong&gt;only be used once&lt;/strong&gt; we have tuned the parameters using the validation set.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;10) What is cross-validation?&lt;/strong&gt;&lt;br&gt;
CV is a statistical &lt;strong&gt;resampling&lt;/strong&gt; technique that uses different parts of the dataset to train and test an ML algorithm on different iterations. The aim of CV provides the ability to estimate model performance on unseen data.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andrewekhalel/MLQuestions&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ML Interview Questions collected by andrewekhalel&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[Career Talk] Topic 1: SDE or DS, How Can I Choose?</title>
        <link>https://tonyfpy.github.io/p/career-talk-topic-1-sde-or-ds-how-can-i-choose/</link>
        <pubDate>Tue, 26 Apr 2022 22:57:49 +0800</pubDate>
        
        <guid>https://tonyfpy.github.io/p/career-talk-topic-1-sde-or-ds-how-can-i-choose/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on April 26th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on April 28th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;Recently, I am preparing for the application of 2023 summer intership in US. Since it might be my last industrial internship, this experience would influence my career path to a large extent and pave the way to my future career development. It&amp;rsquo;s time to conisder it comprehensively.&lt;/p&gt;
&lt;p&gt;I would like to consider myself as a freshman in job hunting, because it&amp;rsquo;s my first time to seek employment in another country. In order to find a desirable job placement, I&amp;rsquo;ve gone through many related materials online. In this post, I&amp;rsquo;m gonna talk about &lt;strong&gt;Software Devlopment(SD)&lt;/strong&gt; and &lt;strong&gt;Data Science(DS)&lt;/strong&gt;, two popular job directions most CS graduates will choose.&lt;/p&gt;
&lt;h2 id=&#34;sd-vs-ds&#34;&gt;SD V.S. DS&lt;/h2&gt;
&lt;h3 id=&#34;number-of-job-opportunities&#34;&gt;Number of Job Opportunities&lt;/h3&gt;
&lt;p&gt;In general, companies offers more job positions for SD than DS evidently. The ratio is about &lt;strong&gt;10 : 1&lt;/strong&gt; in average. SD is &lt;strong&gt;more friendly to new graduates&lt;/strong&gt; than DS in that companies provides more SD placements for them. DS requires the candidates to earn a high education degree or have past working experience.&lt;/p&gt;
&lt;h3 id=&#34;job-categories&#34;&gt;Job Categories&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;SD&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Software Development Engineer&lt;/li&gt;
&lt;li&gt;Application Developer&lt;/li&gt;
&lt;li&gt;Full-stack Web Developer&lt;/li&gt;
&lt;li&gt;Frontend Developer&lt;/li&gt;
&lt;li&gt;Backend Developer&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DS&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Scientist&lt;/li&gt;
&lt;li&gt;Applied Scientist&lt;/li&gt;
&lt;li&gt;Statistician&lt;/li&gt;
&lt;li&gt;Business Intelligence Engineer&lt;/li&gt;
&lt;li&gt;Data/Product/Business Analyst&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Cross Domain&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine Learning Engineer&lt;/li&gt;
&lt;li&gt;Deep Learning Engineer&lt;/li&gt;
&lt;li&gt;Data Engineer&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;salary&#34;&gt;Salary&lt;/h3&gt;
&lt;p&gt;The salary may vary depending on your experience, skills, training, certifications and your employer. In general, SD-related professionals are paid higher than DS-related professionals. Reasearch-oriented DS jobs have higher salaries than other kinds of DS jobs, because they are usually demanding and only open for PhDs.&lt;/p&gt;
&lt;h3 id=&#34;degree-requirements&#34;&gt;Degree Requirements&lt;/h3&gt;
&lt;p&gt;SD: Bachlor&amp;rsquo;s degree or higher &lt;br/&gt;
DS: Master&amp;rsquo;s degree or higher. Many positions even require a Doctoral degree. &lt;br/&gt;&lt;/p&gt;
&lt;h3 id=&#34;hard-skills&#34;&gt;Hard Skills&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;SD&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Algorithm and Data Structure&lt;/li&gt;
&lt;li&gt;Programming Paradigms&lt;/li&gt;
&lt;li&gt;System Design&lt;/li&gt;
&lt;li&gt;Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DS&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Statistics and Machien Learning&lt;/li&gt;
&lt;li&gt;Data Manipulation and Modeling&lt;/li&gt;
&lt;li&gt;Data Visualization&lt;/li&gt;
&lt;li&gt;Experiemnts Design and Analysis&lt;/li&gt;
&lt;li&gt;Business Case&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;soft-skills&#34;&gt;Soft Skills&lt;/h3&gt;
&lt;p&gt;Common soft skills are indispensable for SD and DS in your long-term career development.&lt;/p&gt;
&lt;p&gt;Besides, DS requires the candidates to have &lt;strong&gt;strong communications skills&lt;/strong&gt;, &lt;strong&gt;data-driven decision making&lt;/strong&gt;, &lt;strong&gt;product sense&lt;/strong&gt;, etc.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;job-descriptions&#34;&gt;Job Descriptions&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Job responsibilities vary based on employers&amp;rsquo; requirements and should be learned case by case.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;sd&#34;&gt;SD&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Full-Stack Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Front-End + Back-End&lt;/li&gt;
&lt;li&gt;UI + Server + Database Configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mobile App Developer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Android / IOS&lt;/li&gt;
&lt;li&gt;Memory + Computational Power&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Graphics Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;2D and 3D Digital Platforms for Gaming and Video Production&lt;/li&gt;
&lt;li&gt;Math + CS&lt;/li&gt;
&lt;li&gt;Unity, OpenGL&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embedded Systems Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Control of machines&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Software Development Engineer in Test(SDET)&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Dev + Automated Testing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DevOps Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Dev + Operations + Deployment&lt;/li&gt;
&lt;li&gt;Network or Sys Admin&lt;/li&gt;
&lt;li&gt;Source Control / Infrastructure Automation / Cloud&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ds&#34;&gt;DS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Analysts&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Datasets -&amp;gt; Analysis -&amp;gt; Visulization(Reports / Resentations / &amp;hellip;)&lt;/li&gt;
&lt;li&gt;Experiment (A/B testing) + Statistic + SQL / R / Python&lt;/li&gt;
&lt;li&gt;Product Interpretation + Actionable Insights + Communication&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data Scientist&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Data Manipulation + Statistical Modeling + Machine Learning&lt;/li&gt;
&lt;li&gt;Product Improvement&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Applied Scientist / Research Scientist&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Independent Research + Literature Review&lt;/li&gt;
&lt;li&gt;Model Design + Implementation + Optimization&lt;/li&gt;
&lt;li&gt;Long-term Research&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Quant Researcher&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Finance + Statistics + Coding&lt;/li&gt;
&lt;li&gt;Time Series&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cross-domain&#34;&gt;Cross Domain&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Data Pipeline&lt;/li&gt;
&lt;li&gt;Data Infrastructure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Machine Learning Engineer&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Mathematics + Statistics + Probability&lt;/li&gt;
&lt;li&gt;Data Modeling and Evaluation&lt;/li&gt;
&lt;li&gt;ML System Design&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;www.xiaogeedu.com&#34; &gt;SDE and DS 的求职难度和就业现状&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.ph-education.com/%e7%95%99%e5%ad%a6%e7%94%b3%e8%af%b7/%e5%b9%b2%e8%b4%a7%e7%bb%8f%e9%aa%8c%e5%90%88%e9%9b%86/%e5%b9%b2%e8%b4%a7-%e4%b8%80%e4%b8%aa%e5%85%b8%e5%9e%8b%e5%8c%97%e7%be%8eds-master%e7%9a%84%e6%b1%82%e8%81%8c%e5%85%a8%e8%bf%87%e7%a8%8b%e5%9b%9e%e9%a1%be/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;一个典型北美DS master的求职全过程回顾&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.bilibili.com/video/BV1Sf4y1p79r?spm_id_from=333.880.my_history.page.click&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;疫情下我是如何拿到FB DS offer 的？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.coursera.org/introduction-data-science-careers/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;An introduction to data science careers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://intellipaat.com/blog/data-science-vs-software-engineering/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data Science vs Software Engineering&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.dataapplab.com/differences-between-ds-da-ba-and-de-and-key-points-of-job-interview/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;数据岗位大合集｜DS、DA、BA和DE的区别及求职面试重点&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.1point3acres.com/bbs/thread-850531-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;你为什么不该选择DS - 可能是2022年最详细的劝退贴&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.1point3acres.com/bbs/thread-601652-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Data Science相关岗位全面解析(DS vs DA vs MLE vs DE)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.1point3acres.com/bbs/thread-885801-1-1.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DS找工回顾及资料总结&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://analyticsindiamag.com/a-complete-guide-to-data-science-career-path-by-great-learning-aim/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;A Complete Guide To Data Science Career Path – By Great Learning &amp;amp; AIM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.thinkful.com/blog/software-engineer-career-path/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Software Engineer Career Path&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.geeksforgeeks.org/career-paths-for-software-developers-and-programmers-in-2019/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Career Paths For Software Developers and Programmers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
