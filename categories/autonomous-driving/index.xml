<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Autonomous Driving on Tony Feng</title>
        <link>https://tonyfpy.github.io/categories/autonomous-driving/</link>
        <description>Recent content in Autonomous Driving on Tony Feng</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language><atom:link href="https://tonyfpy.github.io/categories/autonomous-driving/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>[AD Fundamentals] Perception</title>
        <link>https://tonyfpy.github.io/p/ad-fundamentals-perception/</link>
        <pubDate>Tue, 22 Nov 2022 16:20:15 -0500</pubDate>
        
        <guid>https://tonyfpy.github.io/p/ad-fundamentals-perception/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Nov. 22th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Nov. 22th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;This sereis of posts contains notes from the course &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.udacity.com/course/self-driving-car-fundamentals-featuring-apollo--ud0419&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Driving Fundamentals: Featuring Apollo&lt;/a&gt;&lt;/strong&gt; published by &lt;strong&gt;Udacity&lt;/strong&gt; &amp;amp; &lt;strong&gt;Baidu Apollo&lt;/strong&gt;. This course aims to deliver key parts of self-driving cars, including HD Map, localization, perception, prediction, planning and control. I posted these &amp;ldquo;notes&amp;rdquo; (what I&amp;rsquo;ve learnt) for study and review only.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;computer-vision-for-ad&#34;&gt;Computer Vision for AD&lt;/h2&gt;
&lt;h3 id=&#34;detection&#34;&gt;Detection&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Find all pedestrians in the driving record image.&lt;/li&gt;
&lt;li&gt;Localize the position of the traffic light in an image.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Alogorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf?spm=5176.100239.blogcont55892.8.pm8zm1&amp;amp;file=Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1504.08083.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Fast R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1506.01497.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Faster R-CNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1506.02640.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YOLO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1512.02325.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SSD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;classification&#34;&gt;Classification&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Determine if the obstacle in a picture is a pedestrian or a biker.&lt;/li&gt;
&lt;li&gt;Recognize the status of a traffic light.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ![](white.jpg)![](classification.jpg)![](white.jpg) --&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/classification.jpg&#34;
	width=&#34;1122&#34;
	height=&#34;568&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/classification_hufa211ebd315be5d2e35ac8c7fcb1592c_54921_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-perception/classification_hufa211ebd315be5d2e35ac8c7fcb1592c_54921_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;197&#34;
		data-flex-basis=&#34;474px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;tracking&#34;&gt;Tracking&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mark a dangerously driven vehicle on the road.&lt;/li&gt;
&lt;li&gt;Differentiating multiple cars on the road in a sequence of continuous driving record frames.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Why tracking?&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tracking handles occlusion.&lt;/li&gt;
&lt;li&gt;Tracking preserves identity.&lt;/li&gt;
&lt;li&gt;Tracking could be combined with a predictive algorithm to predict the future behavior of a vehicle.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;segmentation&#34;&gt;Segmentation&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Determine which pixels in the image captured by the camera correspond to the travelable area.&lt;/li&gt;
&lt;li&gt;Distinguish lanes and road signs in driving record images&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Alogorithm&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a class=&#34;link&#34; href=&#34;https://arxiv.org/pdf/1411.4038.pdf&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Fully Convolutional Networks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ![](white.jpg)![](FCN.jpg)![](white.jpg) --&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/FCN.jpg&#34;
	width=&#34;1158&#34;
	height=&#34;636&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/FCN_hu55251f95733d4dba1d40be495f619cd2_41317_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-perception/FCN_hu55251f95733d4dba1d40be495f619cd2_41317_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;182&#34;
		data-flex-basis=&#34;436px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;camera-images--lidar-images&#34;&gt;Camera Images &amp;amp; LiDAR Images&lt;/h2&gt;
&lt;h3 id=&#34;camera-images&#34;&gt;Camera Images&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Width * Height * Depth&lt;/li&gt;
&lt;li&gt;Pixel $\leftarrow$ (R, G, B)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lidar-images&#34;&gt;LiDAR Images&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;LiDAR Pulses $\leftarrow$ Point Cloud Representation&lt;/li&gt;
&lt;li&gt;Shape and Surface Texture&lt;/li&gt;
&lt;li&gt;Spatial Info&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;appllo-perception&#34;&gt;Appllo Perception&lt;/h2&gt;
&lt;h3 id=&#34;obstacle-perceptioin&#34;&gt;Obstacle Perceptioin&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ROI Filtering&lt;/li&gt;
&lt;li&gt;3D Object Detection&lt;/li&gt;
&lt;li&gt;Detection to Track Association&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/3DOD.jpg&#34;
	width=&#34;1038&#34;
	height=&#34;456&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/3DOD_hu55ea689bb8c0766424289e4fc972f204_25579_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-perception/3DOD_hu55ea689bb8c0766424289e4fc972f204_25579_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;227&#34;
		data-flex-basis=&#34;546px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;traffic-lights-detection&#34;&gt;Traffic Lights Detection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;HD Map $\leftarrow$ Location of the light&lt;/li&gt;
&lt;li&gt;Detection &amp;amp; Classification&lt;/li&gt;
&lt;li&gt;Matching multiple lights with lane lines&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/LL.jpg&#34;
	width=&#34;1118&#34;
	height=&#34;528&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/LL_hue512f3189380d90b5d184b23bc2631ee_33206_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-perception/LL_hue512f3189380d90b5d184b23bc2631ee_33206_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;211&#34;
		data-flex-basis=&#34;508px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;sensor-data-comparisons&#34;&gt;Sensor Data Comparisons&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/sensor_fusion.jpg&#34;
	width=&#34;1126&#34;
	height=&#34;566&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/sensor_fusion_hu2613074c8a73928e25d7d67d2873ef8b_46459_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-perception/sensor_fusion_hu2613074c8a73928e25d7d67d2873ef8b_46459_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;198&#34;
		data-flex-basis=&#34;477px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;radar&#34;&gt;Radar&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Wavelength in mm&lt;/li&gt;
&lt;li&gt;Can sense non-line of sight objects&lt;/li&gt;
&lt;li&gt;Can currently directly measure velocity&lt;/li&gt;
&lt;li&gt;Low Resolution&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;lirar&#34;&gt;LiRAR&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Wavelength in infrared&lt;/li&gt;
&lt;li&gt;Higher Resolution&lt;/li&gt;
&lt;li&gt;Most affected by dirt and small debris&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;perception-fusion-strategy&#34;&gt;Perception Fusion Strategy&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/kalman_filter.jpg&#34;
	width=&#34;1020&#34;
	height=&#34;548&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-perception/kalman_filter_hu38f1ed307f8734fc67fa20ecbd189b0c_32753_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-perception/kalman_filter_hu38f1ed307f8734fc67fa20ecbd189b0c_32753_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;186&#34;
		data-flex-basis=&#34;446px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AD Fundamentals] Localization</title>
        <link>https://tonyfpy.github.io/p/ad-fundamentals-localization/</link>
        <pubDate>Sun, 30 Oct 2022 16:02:49 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/ad-fundamentals-localization/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 30th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Nov 21st, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;This sereis of posts contains notes from the course &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.udacity.com/course/self-driving-car-fundamentals-featuring-apollo--ud0419&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Driving Fundamentals: Featuring Apollo&lt;/a&gt;&lt;/strong&gt; published by &lt;strong&gt;Udacity&lt;/strong&gt; &amp;amp; &lt;strong&gt;Baidu Apollo&lt;/strong&gt;. This course aims to deliver key parts of self-driving cars, including HD Map, localization, perception, prediction, planning and control. I posted these &amp;ldquo;notes&amp;rdquo; (what I&amp;rsquo;ve learnt) for study and review only.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;intro-to-localization&#34;&gt;Intro to Localization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;It makes the car know where it is.&lt;/li&gt;
&lt;li&gt;It compares the data observed from vehicle sensors and the data on the HD map to match its position.&lt;/li&gt;
&lt;li&gt;Vehicle coordinate frame $\Longleftrightarrow$ data transformation $\Longleftrightarrow$ map coordinate frame&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/coordinate.jpg&#34;
	width=&#34;1124&#34;
	height=&#34;620&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/coordinate_hud65c133f53f97bea3199aa4d5cf15836_53896_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/coordinate_hud65c133f53f97bea3199aa4d5cf15836_53896_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;181&#34;
		data-flex-basis=&#34;435px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;gnss-rtk&#34;&gt;GNSS RTK&lt;/h2&gt;
&lt;p&gt;A GPS receiver capable of &lt;strong&gt;Real-time kinematic positioning&lt;/strong&gt; (RTK) takes in the normal signals from the &lt;strong&gt;Global Navigation Satellite Systems&lt;/strong&gt; (GNSS) along with a correction stream to achieve centimeter-level positional accuracy.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/RTK.jpg&#34;
	width=&#34;1124&#34;
	height=&#34;624&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/RTK_hu19ead76b1306ebe36460fe2f16adb6ed_46083_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/RTK_hu19ead76b1306ebe36460fe2f16adb6ed_46083_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;180&#34;
		data-flex-basis=&#34;432px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;triangulation&#34;&gt;Triangulation&lt;/h3&gt;
&lt;p&gt;Triangulation is a method for calculating a position that relies on a known &lt;strong&gt;distance&lt;/strong&gt; between &lt;strong&gt;two&lt;/strong&gt; measuring apparatuses and the measured &lt;strong&gt;angles&lt;/strong&gt; from those two points to an object. This works using the angle-side-angle triangle congruency theorem to the find the location of an object.&lt;/p&gt;
&lt;h3 id=&#34;trilateration&#34;&gt;Trilateration&lt;/h3&gt;
&lt;p&gt;Trilateration is the more common method for position calculations. Trilateration uses the known &lt;strong&gt;distance&lt;/strong&gt; from at least &lt;strong&gt;three fixed points in 2D space&lt;/strong&gt; or &lt;strong&gt;four fixed points in 3D space&lt;/strong&gt; (as if on the surface of the Earth) to calculate the position of an object. Trilateration works by finding the intersection of a series of circles (imagine in a Venn diagram).&lt;/p&gt;
&lt;h3 id=&#34;global-positioning-system-gps&#34;&gt;Global Positioning System (GPS)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Components&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Satellite&lt;/li&gt;
&lt;li&gt;Control Stations
&lt;ul&gt;
&lt;li&gt;It keeps the system running and verify the accuracy of the signals.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;GPS receiver
&lt;ul&gt;
&lt;li&gt;It exists in mobile phones, computers, cars, etc.&lt;/li&gt;
&lt;li&gt;It shoud be able to detect &amp;gt;= 4 GPS satellites at one under appropriate environment.&lt;/li&gt;
&lt;li&gt;It uses &lt;strong&gt;time of fight&lt;/strong&gt; (ToF) to measure the distance.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Pros &amp;amp; Cons&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accurate with RTK&lt;/li&gt;
&lt;li&gt;Poor performance in urban area and canyons&lt;/li&gt;
&lt;li&gt;Low frequency update&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;inertial-navigation&#34;&gt;Inertial Navigation&lt;/h2&gt;
&lt;h3 id=&#34;basic-idea&#34;&gt;Basic Idea&lt;/h3&gt;
&lt;p&gt;Acceleration, initial velocity, initial position could be used to calculate the velocity and location of the car.&lt;/p&gt;
&lt;h3 id=&#34;inertial-measurement-unit-imu&#34;&gt;Inertial Measurement Unit (IMU)&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Components&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accelerometer&lt;/li&gt;
&lt;li&gt;Gyroscope&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Pros &amp;amp; Cons&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;High frequncy update $\rightarrow$ Real-time Location Info&lt;/li&gt;
&lt;li&gt;Motion error increases with time&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;lidar-localization&#34;&gt;LiDAR Localization&lt;/h2&gt;
&lt;h3 id=&#34;point-cloud-matching&#34;&gt;Point Cloud Matching&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Errors&lt;/strong&gt; produced when matching point cloud measurement with HD map
&lt;ul&gt;
&lt;li&gt;The # of points collected by LiDAR&lt;/li&gt;
&lt;li&gt;Moving objects, such as cars, pedestrians, etc.&lt;/li&gt;
&lt;li&gt;The transformation of point cloud measurement&lt;/li&gt;
&lt;li&gt;Error produced by LiDAR itself&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iterative Closest Point&lt;/strong&gt; Algorithms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Filter&lt;/strong&gt; Algorithms
&lt;ul&gt;
&lt;li&gt;Histogram filter&lt;/li&gt;
&lt;li&gt;Kalman  filter&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pros--cons&#34;&gt;Pros &amp;amp; Cons&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Robustness&lt;/li&gt;
&lt;li&gt;Maintaining up-to-date HD maps&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;visual-localization&#34;&gt;Visual Localization&lt;/h2&gt;
&lt;h3 id=&#34;visual-data&#34;&gt;Visual Data&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Usually we combine &lt;strong&gt;camera data with a map and GPS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Partical Filter&lt;/strong&gt; Algorithms
&lt;ul&gt;
&lt;li&gt;Observations&lt;/li&gt;
&lt;li&gt;Probability&lt;/li&gt;
&lt;li&gt;Map&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;pros--cons-1&#34;&gt;Pros &amp;amp; Cons&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Camera data is easy to obtain&lt;/li&gt;
&lt;li&gt;Lack of 3D Info&lt;/li&gt;
&lt;li&gt;Reliance on 3D maps&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;apollo-localization&#34;&gt;Apollo Localization&lt;/h2&gt;
&lt;h3 id=&#34;multi-sensor-fusion&#34;&gt;Multi-sensor Fusion&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;GPS&lt;/li&gt;
&lt;li&gt;IMU&lt;/li&gt;
&lt;li&gt;LiDAR&lt;/li&gt;
&lt;li&gt;Radar&lt;/li&gt;
&lt;li&gt;HD Maps&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;kalman-filter&#34;&gt;Kalman Filter&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/kalman-filter.jpg&#34;
	width=&#34;1124&#34;
	height=&#34;780&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/kalman-filter_hu10a07b120acce79578111e0bdef53a28_39933_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/kalman-filter_hu10a07b120acce79578111e0bdef53a28_39933_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;144&#34;
		data-flex-basis=&#34;345px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-localization/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AD Fundamentals] High-Definition Maps</title>
        <link>https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/</link>
        <pubDate>Sat, 29 Oct 2022 20:32:50 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 29th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 30th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;This sereis of posts contains notes from the course &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.udacity.com/course/self-driving-car-fundamentals-featuring-apollo--ud0419&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Driving Fundamentals: Featuring Apollo&lt;/a&gt;&lt;/strong&gt; published by &lt;strong&gt;Udacity&lt;/strong&gt; &amp;amp; &lt;strong&gt;Baidu Apollo&lt;/strong&gt;. This course aims to deliver key parts of self-driving cars, including HD Map, localization, perception, prediction, planning and control. I posted these &amp;ldquo;notes&amp;rdquo; (what I&amp;rsquo;ve learnt) for study and review only.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hd-maps&#34;&gt;HD Maps&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Accurate 3D representation of the road network
&lt;ul&gt;
&lt;li&gt;e.g. layout of intersections, locations of signposts&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Semantic info
&lt;ul&gt;
&lt;li&gt;e.g. traffic light, speed limit, lane rules&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;3D model of the city
&lt;ul&gt;
&lt;li&gt;e.g. roads, buildings, tunnels&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;localization-percpeption-and-planning&#34;&gt;Localization, Percpeption and Planning&lt;/h2&gt;
&lt;h3 id=&#34;localization-with-hd-maps&#34;&gt;Localization with HD Maps&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Comparisons between observed data and data in the HD map&lt;/li&gt;
&lt;li&gt;Preprocessing, coordinate transformation, data fusion&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;perception-with-hd-maps&#34;&gt;Perception with HD Maps&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;HD maps help the car&amp;rsquo;s next decions.
&lt;ul&gt;
&lt;li&gt;Sensors have limits in different situations&lt;/li&gt;
&lt;li&gt;Camera is affected by bad whether and dark environment.&lt;/li&gt;
&lt;li&gt;Other sensors may not detect what is behind the obstacle.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HD maps can narrow the detection scope.
&lt;ul&gt;
&lt;li&gt;Region of Interest (ROI) helps improve speed and accuracy.&lt;/li&gt;
&lt;li&gt;Region of Interest (ROI) helps to save the computation resources.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;planning-with-hd-maps&#34;&gt;Planning with HD Maps&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;HD Maps help to find suitable driving space.&lt;/li&gt;
&lt;li&gt;HD Maps help to identify different possible routing options and find best maneuver.&lt;/li&gt;
&lt;li&gt;HD Maps help to forecast future locations for other vehicles on the road.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;apollo-hd-maps&#34;&gt;Apollo HD Maps&lt;/h2&gt;
&lt;h3 id=&#34;road-definitions&#34;&gt;Road Definitions&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/AHDM.jpg&#34;
	width=&#34;1000&#34;
	height=&#34;482&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/AHDM_hu22a08059939e36906b453b9b84a406a1_68883_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/AHDM_hu22a08059939e36906b453b9b84a406a1_68883_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;207&#34;
		data-flex-basis=&#34;497px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-high-definition-maps/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;/p&gt;
&lt;h3 id=&#34;standard-vs-apollo-opendrive&#34;&gt;Standard vs. Apollo OpenDRIVE&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Main Difference&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Standard OpenDRIVE&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;Apollo OpenDRIVE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Application Scenario&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Simulation scenarios&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Real-world scenes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Elemental Form Expression&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Reference line&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Absolute coordinate sequences&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Elemental Richness&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Common elements&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;More expressions and attributes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Adaptive Driverless Algorithm&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;N/A&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;Integrate Baidu’s driverless experience&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hd-maps-construction&#34;&gt;HD Maps Construction&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Data Sourcing
&lt;ul&gt;
&lt;li&gt;Survey vehicle with GPS, IMU, Antenna, LiDAR, Camera&lt;/li&gt;
&lt;li&gt;Crowdsourcing with mobile devices, in-car devices, connected cars, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Data Processing
&lt;ul&gt;
&lt;li&gt;Form an inital map template by data sorting, classfiying, cleansing&lt;/li&gt;
&lt;li&gt;Without semantic info and annotations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Object Detection
&lt;ul&gt;
&lt;li&gt;Detect and classify static objects&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Manual Verification
&lt;ul&gt;
&lt;li&gt;Ensure the automated map creation correctly&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map Products
&lt;ul&gt;
&lt;li&gt;Top-down view localication maps&lt;/li&gt;
&lt;li&gt;3D point cloud maps&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        <item>
        <title>[AD Fundamentals] An Overview of Baidu Apollo</title>
        <link>https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/</link>
        <pubDate>Sat, 29 Oct 2022 16:07:45 -0400</pubDate>
        
        <guid>https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;Authored by Tony Feng&lt;/p&gt;
&lt;p&gt;Created on Oct 29th, 2022&lt;/p&gt;
&lt;p&gt;Last Modified on Oct 30th, 2022&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;intro&#34;&gt;Intro&lt;/h2&gt;
&lt;p&gt;This sereis of posts contains notes from the course &lt;strong&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.udacity.com/course/self-driving-car-fundamentals-featuring-apollo--ud0419&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Self-Driving Fundamentals: Featuring Apollo&lt;/a&gt;&lt;/strong&gt; published by &lt;strong&gt;Udacity&lt;/strong&gt; &amp;amp; &lt;strong&gt;Baidu Apollo&lt;/strong&gt;. This course aims to deliver key parts of self-driving cars, including HD Map, localization, perception, prediction, planning and control. I posted these &amp;ldquo;notes&amp;rdquo; (what I&amp;rsquo;ve learnt) for study and review only.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;what-is-self-driving&#34;&gt;What is Self-Driving?&lt;/h2&gt;
&lt;h3 id=&#34;why-self-driving-cars&#34;&gt;Why Self-Driving Cars?&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Human&lt;/th&gt;
&lt;th style=&#34;text-align:center&#34;&gt;Self-Driving Car&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;High Traffic Accident Rate&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;More Reliable Driving&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Learn to Drive From Scratch&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Learnable Driving Sys&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:center&#34;&gt;Parking Trouble&lt;/td&gt;
&lt;td style=&#34;text-align:center&#34;&gt;No Parking Trouble&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;levels-of-ad&#34;&gt;Levels of AD&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Level 1 (Driver Assistance)
&lt;ul&gt;
&lt;li&gt;Driver fully engaged&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Level 2 (Partial Automation)
&lt;ul&gt;
&lt;li&gt;Auto cruise control&lt;/li&gt;
&lt;li&gt;Auto lane keeping&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Level 3 (Conditional Automation)
&lt;ul&gt;
&lt;li&gt;Human take over whenever necessary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Level 4 (No Human Interference)
&lt;ul&gt;
&lt;li&gt;Without sterring wheel, throttle or brake&lt;/li&gt;
&lt;li&gt;Restricted in geofence (certain areas)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Level 5 (Full Automation)
&lt;ul&gt;
&lt;li&gt;Better than human in all scenarios&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;how-self-driving-cars-work&#34;&gt;How Self-Driving Cars Work?&lt;/h2&gt;
&lt;h3 id=&#34;key-components&#34;&gt;Key Components&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Computer Vision
&lt;ul&gt;
&lt;li&gt;How the car sees the world&lt;/li&gt;
&lt;li&gt;e.g. bounding boxes, contour, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Sensor Fusion
&lt;ul&gt;
&lt;li&gt;How the car understands the around situtaions&lt;/li&gt;
&lt;li&gt;e.g. distance, relative velocity, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Localization
&lt;ul&gt;
&lt;li&gt;How the car learns where it is&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Path Planning
&lt;ul&gt;
&lt;li&gt;How the car figures out where to go&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Control
&lt;ul&gt;
&lt;li&gt;How the car follows the path or reacts to various situations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;apollo-structure&#34;&gt;Apollo Structure&lt;/h3&gt;
&lt;p&gt;Apollo’s system centers around HD Maps and Localization. The other components of the system revolve around Perception, Prediction, Planning and Control.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/apollo-structure.jpg&#34;
	width=&#34;1153&#34;
	height=&#34;759&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/apollo-structure_huf49d23a28b0baffc3fbc142237b37f34_48159_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/apollo-structure_huf49d23a28b0baffc3fbc142237b37f34_48159_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;151&#34;
		data-flex-basis=&#34;364px&#34;
	
&gt;&lt;img src=&#34;https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/white.jpg&#34;
	width=&#34;285&#34;
	height=&#34;340&#34;
	srcset=&#34;https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_480x0_resize_q75_box.jpg 480w, https://tonyfpy.github.io/p/ad-fundamentals-an-overview-of-baidu-apollo/white_hu0053ed58c52b0a79a00a3298e4f2752e_2127_1024x0_resize_q75_box.jpg 1024w&#34;
	loading=&#34;lazy&#34;
	
	
		class=&#34;gallery-image&#34; 
		data-flex-grow=&#34;83&#34;
		data-flex-basis=&#34;201px&#34;
	
&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;hardware&#34;&gt;Hardware&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Controller Area Network (CAN)
&lt;ul&gt;
&lt;li&gt;Vehicle&amp;rsquo;s internal communication network&lt;/li&gt;
&lt;li&gt;Signal transmission for acceleration, braking and steering, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Global Positioning System (GPS)
&lt;ul&gt;
&lt;li&gt;Location&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Inertial Measurement Unit (IMU)
&lt;ul&gt;
&lt;li&gt;Speed, acceleration and other factors&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LiDAR is an array of pulse lasers,
&lt;ul&gt;
&lt;li&gt;The reflection of this laser beams builds the point cloud for enviroment understanding.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Camera
&lt;ul&gt;
&lt;li&gt;Visual data capturing&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Radar
&lt;ul&gt;
&lt;li&gt;Obstacle detection&lt;/li&gt;
&lt;li&gt;Low resolution but economical and robust to different wheather/lighting conditions&lt;/li&gt;
&lt;li&gt;Speed measuring of other vehicles&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;open-software-stack&#34;&gt;Open Software Stack&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Real-time Operating Sys (ROTS)
&lt;ul&gt;
&lt;li&gt;It can produce timely calculations, analysis and execute decisions in a short time.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Runtime Framework
&lt;ul&gt;
&lt;li&gt;A customized version of Robot Operating System (ROS)&lt;/li&gt;
&lt;li&gt;Modules are independent.&lt;/li&gt;
&lt;li&gt;Shared memory for decentralization and data comparability (Protobuf)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Application modules
&lt;ul&gt;
&lt;li&gt;MAP engine&lt;/li&gt;
&lt;li&gt;Localization, Perception, Planning, Control,&lt;/li&gt;
&lt;li&gt;End-to-end driving&lt;/li&gt;
&lt;li&gt;Human-machine interface (HMI)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;cloud-service&#34;&gt;Cloud Service&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Data Storage&lt;/li&gt;
&lt;li&gt;Multiple Tools
&lt;ul&gt;
&lt;li&gt;HD map&lt;/li&gt;
&lt;li&gt;Simulation&lt;/li&gt;
&lt;li&gt;Data platform&lt;/li&gt;
&lt;li&gt;Security&lt;/li&gt;
&lt;li&gt;Over-the-air software updates (OTA)&lt;/li&gt;
&lt;li&gt;Intelligent voice system (DuerOS)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
</description>
        </item>
        
    </channel>
</rss>
